{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare SI-method with roll damping DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from jupyterthemes import jtplot\n",
    "#jtplot.style(theme='onedork', context='notebook', ticks=True, grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.style.use('paper')\n",
    "\n",
    "#import data\n",
    "import copy\n",
    "from rolldecay.bis_system import BisSystem\n",
    "from rolldecay import database\n",
    "\n",
    "import rolldecayestimators.lambdas as lambdas\n",
    "from rolldecayestimators.substitute_dynamic_symbols import run, lambdify, significant_numbers\n",
    "from rolldecayestimators.ikeda_estimator import IkedaQuadraticEstimator\n",
    "\n",
    "from rolldecay.paper_writing import save_fig\n",
    "from rolldecay.froude_scaling import froude_scale\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from latex_helpers import pylatex_extenders\n",
    "import rolldecay\n",
    "from rolldecay.paper_writing import save_fig\n",
    "import rolldecayestimators.simplified_ikeda as si\n",
    "import rolldecayestimators.sensitivity as sensitivity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from rolldecayestimators.measure import linearized_matrix\n",
    "\n",
    "\n",
    "print(matplotlib.matplotlib_fname())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = database.get_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ikeda = database.load(rolldecay_table_name='rolldecay_simplified_ikeda', limit_score=0.5, \n",
    "                             exclude_table_name='rolldecay_exclude')\n",
    "\n",
    "df_rolldecay = database.load(rolldecay_table_name='rolldecay_quadratic_b', limit_score=0.9, \n",
    "                             exclude_table_name='rolldecay_exclude')\n",
    "\n",
    "#df_rolldecay = database.load(rolldecay_table_name='rolldecay_linear_b', limit_score=0.9, \n",
    "#                             exclude_table_name='rolldecay_exclude')\n",
    "#df_rolldecay['B_2']=0\n",
    "\n",
    "df_rolldecay['ship_speed']*=1.852/3.6\n",
    "df_ikeda['ship_speed']*=1.852/3.6\n",
    "\n",
    "description = pd.read_sql_table('description', con=db.engine, index_col='id')\n",
    "description.loc['ship_speed','unit']='m/s'\n",
    "description.loc['VDES','unit']='m/s'\n",
    "description.loc['Disp'] = {'description':'Ship discplacement','unit':'m3'}\n",
    "\n",
    "T_f=df_rolldecay['TF']\n",
    "T_a=df_rolldecay['TA']\n",
    "L_pp=df_rolldecay['lpp']\n",
    "df_rolldecay['trim']=np.arctan((T_a-T_f)/L_pp)\n",
    "mask = df_rolldecay['trim'].abs() < np.deg2rad(0.3)\n",
    "df_rolldecay=df_rolldecay.loc[mask].copy()\n",
    "\n",
    "df_ikeda['Disp']=df_ikeda['Volume']\n",
    "df_rolldecay['Disp']=df_rolldecay['Volume']\n",
    "\n",
    "skip=['omega0']\n",
    "df_ikeda = froude_scale(data=df_ikeda, description=description, skip=skip)\n",
    "df_rolldecay = froude_scale(data=df_rolldecay, description=description, skip=skip)\n",
    "\n",
    "#phi_a = np.deg2rad(3)\n",
    "\n",
    "g = 9.81\n",
    "rho=1000\n",
    "\n",
    "#phi_a = df_ikeda['phi_start'].abs()\n",
    "#phi_a = np.deg2rad(2)\n",
    "#df_ikeda['B_e'] = run(function=lambdas.B_e_lambda, inputs=df_ikeda, phi_a=phi_a)\n",
    "#df_ikeda['B_e_hat'] = run(function=lambdas.B_e_hat_lambda, inputs=df_ikeda, g=g, rho=rho)\n",
    "#\n",
    "#phi_a = df_rolldecay['phi_start'].abs()\n",
    "#phi_a = np.deg2rad(2)\n",
    "#df_rolldecay['B_e'] = run(function=lambdas.B_e_lambda, inputs=df_rolldecay, phi_a=phi_a)\n",
    "#df_rolldecay['B_e_hat'] = run(function=lambdas.B_e_hat_lambda, inputs=df_rolldecay, g=g, rho=rho)\n",
    "#\n",
    "#df_rolldecay['omega0_hat'] = run(function=lambdas.omega0_lambda, inputs=df_rolldecay, g=g)\n",
    "#df_ikeda['omega0_hat'] = run(function=lambdas.omega0_lambda, inputs=df_ikeda, g=g)\n",
    "#\n",
    "df_rolldecay['V']=df_rolldecay['ship_speed']\n",
    "df_ikeda['V']=df_ikeda['ship_speed']\n",
    "\n",
    "\n",
    "#df_ikeda['scale_factor']=df_ikeda['lpp']\n",
    "#df_ikeda = froude_scale(data=df_ikeda, description=description, skip=skip)\n",
    "#df_rolldecay['scale_factor']=df_rolldecay['lpp']\n",
    "#df_rolldecay = froude_scale(data=df_rolldecay, description=description, skip=skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_compare = pd.merge(left=df_rolldecay, right=df_ikeda, how = 'inner',left_index=True, right_index=True,\n",
    "#                      suffixes=('','_ikeda'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ikeda(df_rolldecay, verify_input=True, limit_inputs=False):\n",
    "    df=pd.DataFrame()\n",
    "    for run_id, data in df_rolldecay.iterrows():\n",
    "        ikeda_estimator = IkedaQuadraticEstimator(**data, verify_input=verify_input, \n",
    "                                                  limit_inputs=limit_inputs)\n",
    "        try:\n",
    "            ikeda_estimator.fit()\n",
    "        except si.SimplifiedIkedaInputError:\n",
    "            continue\n",
    "        \n",
    "        result = ikeda_estimator.result_for_database(score=False)\n",
    "        result = pd.Series(result, name=run_id)\n",
    "        df=df.append(result)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_rolldecay['ship_speed'].round(decimals=2)==0\n",
    "df_roll_decay_zero = df_rolldecay.loc[mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_no_verify=run_ikeda(df_rolldecay=df_roll_decay_zero, verify_input=False)\n",
    "result_limited=run_ikeda(df_rolldecay=df_roll_decay_zero, verify_input=True, limit_inputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steal=['beam','Disp']\n",
    "df_no_verify = pd.merge(left=result_no_verify, right=df_roll_decay_zero[steal], how='inner', \n",
    "                        left_index=True, right_index=True)\n",
    "\n",
    "df_limited = pd.merge(left=result_limited, right=df_roll_decay_zero[steal], how='inner', \n",
    "                        left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_verify = linearized_matrix(df_rolldecay=df_rolldecay, df_ikeda=df_no_verify)\n",
    "df_limited = linearized_matrix(df_rolldecay=df_rolldecay, df_ikeda=df_limited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_no_verify['B_e_hat'] = run(function=lambdas.B_e_hat_lambda, inputs=df_no_verify, g=g, rho=rho)\n",
    "#df_limited['B_e_hat'] = run(function=lambdas.B_e_hat_lambda, inputs=df_limited, g=g, rho=rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_no_verify = pd.merge(left=df_no_verify, right=df_roll_decay_zero, how='inner', \n",
    "#                        left_index=True, right_index=True, suffixes=('_ikeda',''))\n",
    "#\n",
    "#df_limited = pd.merge(left=df_limited, right=df_roll_decay_zero, how='inner', \n",
    "#                        left_index=True, right_index=True, suffixes=('_ikeda',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_no_verify['error']=df_no_verify['B_e_hat']-df_no_verify['B_e_hat_ikeda']\n",
    "#df_limited['error']=df_limited['B_e_hat']-df_limited['B_e_hat_ikeda']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "x=df_no_verify['B_e_hat']\n",
    "y=df_no_verify['B_e_hat_ikeda']\n",
    "ax.plot(x, y, 'o', alpha=0.5, label='no verify')\n",
    "\n",
    "x=df_limited['B_e_hat']\n",
    "y=df_limited['B_e_hat_ikeda']\n",
    "ax.plot(x, y, 'x', alpha=0.5, label='limited')\n",
    "\n",
    "ax.set_xlabel('$\\hat{B_e}$ (model test)')\n",
    "ax.set_ylabel('$\\hat{B_e}$ (Simplified Ikeda)')\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "lim = np.max([xlim[1],ylim[1]])\n",
    "ax.set_xlim(0,lim)\n",
    "ax.set_ylim(0,lim)\n",
    "ax.plot([0,lim],[0,lim],'r-')\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax.legend()\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_true=df_no_verify['B_e_hat'], y_pred=df_no_verify['B_e_hat_ikeda'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_true=df_limited['B_e_hat'], y_pred=df_limited['B_e_hat_ikeda'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df_rolldecay.copy()\n",
    "#scale_factor=df.scale_factor\n",
    "#df['lpp']/=scale_factor\n",
    "#df['TA']/=scale_factor \n",
    "#df['TF']/=scale_factor\n",
    "#df['beam']/=scale_factor\n",
    "#df['BKL']/=scale_factor\n",
    "#df['BKB']/=scale_factor\n",
    "##df['A0']=db_run.loading_condition.A0\n",
    "#df['kg']/=scale_factor\n",
    "#df['Volume']/=(scale_factor**3)\n",
    "#df['gm']/=scale_factor \n",
    "#df['V']=df['ship_speed']*1.852/3.6/np.sqrt(scale_factor)  #[m/s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rolldecay['V']=df_rolldecay['ship_speed']\n",
    "result_no_verify=run_ikeda(df_rolldecay=df_rolldecay, verify_input=False)\n",
    "result_limited=run_ikeda(df_rolldecay=df_rolldecay, verify_input=True, limit_inputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steal=['beam','Disp']\n",
    "df_no_verify = pd.merge(left=result_no_verify, right=df_rolldecay[steal], how='inner', \n",
    "                        left_index=True, right_index=True)\n",
    "\n",
    "df_limited = pd.merge(left=result_limited, right=df_rolldecay[steal], how='inner', \n",
    "                        left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_verify = linearized_matrix(df_rolldecay=df_rolldecay, df_ikeda=df_no_verify)\n",
    "df_limited = linearized_matrix(df_rolldecay=df_rolldecay, df_ikeda=df_limited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_no_verify['B_e_hat'] = run(function=lambdas.B_e_hat_lambda, inputs=df_no_verify, g=g, rho=rho)\n",
    "#df_limited['B_e_hat'] = run(function=lambdas.B_e_hat_lambda, inputs=df_limited, g=g, rho=rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_no_verify = pd.merge(left=df_no_verify, right=df_rolldecay, how='inner', \n",
    "#                        left_index=True, right_index=True, suffixes=('_ikeda',''))\n",
    "#\n",
    "#df_limited = pd.merge(left=df_limited, right=df_rolldecay, how='inner', \n",
    "#                        left_index=True, right_index=True, suffixes=('_ikeda',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_no_verify['error']=df_no_verify['B_e_hat']-df_no_verify['B_e_hat_ikeda']\n",
    "#df_limited['error']=df_limited['B_e_hat']-df_limited['B_e_hat_ikeda']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "x=df_no_verify['B_e_hat']\n",
    "y=df_no_verify['B_e_hat_ikeda']\n",
    "ax.plot(x, y, '.', label='unlimited')\n",
    "\n",
    "x=df_limited['B_e_hat']\n",
    "y=df_limited['B_e_hat_ikeda']\n",
    "ax.plot(x, y, 'x',label='limited')\n",
    "\n",
    "ax.set_xlabel('$\\hat{B}_e^{Model}$')\n",
    "ax.set_ylabel('$\\hat{B}_e^{SI}$')\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "lim = np.max([xlim[1],ylim[1]])\n",
    "ax.set_xlim(0,lim)\n",
    "ax.set_ylim(0,lim)\n",
    "ax.plot([0,lim],[0,lim],'r-')\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "save_fig(fig=fig, name='ikeda_limited')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_limited.copy()\n",
    "df['abs(error)']=df['error'].abs()\n",
    "df.sort_values(by='abs(error)', ascending=False, inplace=True)\n",
    "df.head()\n",
    "df.to_csv('bad_simplified_ikeda.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "x=df_limited['B_e_hat']\n",
    "y=df_limited['B_e_hat_ikeda']\n",
    "ax.plot(x, y, '.', alpha=0.5, label='limited')\n",
    "\n",
    "ax.set_xlabel('$\\hat{B_e}$ (model test)')\n",
    "ax.set_ylabel('$\\hat{B_e}$ (Simplified Ikeda)')\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "lim = np.max([xlim[1],ylim[1]])\n",
    "ax.set_xlim(0,lim)\n",
    "ax.set_ylim(0,lim)\n",
    "ax.plot([0,lim],[0,lim],'r-')\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax.legend()\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limited.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "x = df_no_verify['B_W_HAT']/df_limited['B_W_HAT']\n",
    "y = df_no_verify['error']\n",
    "ax.plot(x, y,'x', alpha=0.5)\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "x = df_no_verify['B_E_HAT']/df_limited['B_E_HAT']\n",
    "y = df_no_verify['error']\n",
    "ax.plot(x, y,'x', alpha=0.5)\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "x = df_no_verify['B_L_HAT']/df_limited['B_L_HAT']\n",
    "y = df_no_verify['error']\n",
    "ax.plot(x, y,'x', alpha=0.5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes=plt.subplots(ncols=2)\n",
    "ax=axes[0]\n",
    "x=-df_no_verify['error']/df_no_verify['B_e_hat']\n",
    "\n",
    "y=df_no_verify['B_W_HAT']\n",
    "ax.plot(x,y,'.',label='$\\hat{B_W}$')\n",
    "\n",
    "y=df_no_verify['B_E_HAT']\n",
    "ax.plot(x,y,'x',label='$\\hat{B_E}$')\n",
    "\n",
    "y=df_no_verify['B_L_HAT']\n",
    "ax.plot(x,y,'+',label='$\\hat{B_L}$')\n",
    "\n",
    "y=df_no_verify['B_BK_HAT']\n",
    "ax.plot(x,y,'*',label='$\\hat{B_{BK}}$')\n",
    "ax.set_xlabel(r'$ \\frac{\\hat{B_e}(Ikeda) - \\hat{B_e}(model)}{\\hat{B_e}(model)} $')\n",
    "#ax.legend()\n",
    "ax.grid()\n",
    "ax.set_title('unlimited')\n",
    "\n",
    "ax=axes[1]\n",
    "x=-df_limited['error']/df_limited['B_e_hat']\n",
    "\n",
    "y=df_limited['B_W_HAT']\n",
    "ax.plot(x,y,'.',label='$\\hat{B_W}$')\n",
    "\n",
    "y=df_limited['B_E_HAT']\n",
    "ax.plot(x,y,'x',label='$\\hat{B_E}$')\n",
    "\n",
    "y=df_limited['B_L_HAT']\n",
    "ax.plot(x,y,'+',label='$\\hat{B_L}$')\n",
    "\n",
    "y=df_limited['B_BK_HAT']\n",
    "ax.plot(x,y,'*',label='$\\hat{B_{BK}}$')\n",
    "ax.set_xlabel(r'$ \\frac{\\hat{B_e}(Ikeda) - \\hat{B_e}(model)}{\\hat{B_e}(model)} $')\n",
    "\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "ax.set_title('limited')\n",
    "ax.set_xlim(axes[0].get_xlim())\n",
    "ax.set_ylim(axes[0].get_ylim())\n",
    "save_fig(fig=fig, name='ikeda_components')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "df_limited['B_1'].hist(ax=ax)\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "df_limited['B_2'].hist(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "df_limited['B_1_ikeda'].hist(ax=ax)\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "df_limited['B_2_ikeda'].hist(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "df_limited.plot(x='ship_speed', y='error', ax=ax, style='o', alpha=0.5)\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "df_limited[r'T/B']=df_limited['TA']/df_limited['beam']\n",
    "df_limited.plot(x=r'T/B', y='error', ax=ax, style='o', alpha=0.5)\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "df_limited.plot(x=r'omega0_hat', y='error', ax=ax, style='o', alpha=0.5)\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "df_limited['phi_max']=df_limited['phi_start'].abs()\n",
    "df_limited.plot(x=r'phi_max', y='error', ax=ax, style='o', alpha=0.5)\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "df_limited.plot(x=r'B_W_HAT', y='error', ax=ax, style='o', alpha=0.5)\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "df_limited['Cb']=df_limited['Disp']/(df_limited['lpp']*df_limited['beam']*df_limited['TA'])\n",
    "df_limited.plot(x='Cb', y='error', ax=ax, style='o', alpha=0.5)\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "df_limited['OG']=df_limited['kg']-df_limited['TA']\n",
    "df_limited.plot(x='OG', y='error', ax=ax, style='o', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_true=df_no_verify['B_e_hat'], y_pred=df_no_verify['B_e_hat_ikeda'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_true=df_limited['B_e_hat'], y_pred=df_limited['B_e_hat_ikeda'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_limits(row):\n",
    "    draught=(row['TA']+row['TF'])/2\n",
    "    OG=row['kg']-draught\n",
    "    CB=row['Disp']/(row['lpp']*row['beam']*draught)\n",
    "    \n",
    "    limits = si._calculate_limit_value(LPP=row['lpp'], Beam=row['beam'], DRAFT=draught)\n",
    "    s = pd.Series(limits, name=row.name)\n",
    "    return s\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limits = df_limited.apply(func=calculate_limits, axis=1)\n",
    "df=pd.concat([df_limited,limits], axis=1)\n",
    "draught=(df['TA']+df['TF'])/2\n",
    "df['OG']=df['kg']-draught\n",
    "df['CB']=df['Disp']/(df['lpp']*df['beam']*draught)\n",
    "df['CMID']=df['A0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selection = df.copy()\n",
    "for key,limits in si.limits_kawahara.items():\n",
    "    fig,ax=plt.subplots()\n",
    "    bins=np.linspace(df[key].min(), df[key].max(),30)\n",
    "    df[key].hist(ax=ax, bins=bins, label='model test data')\n",
    "    mask = ((df_selection[key] >= limits[0]) & (df_selection[key] <= limits[1]) |\n",
    "           (df_selection[key] == 0)\n",
    "           )\n",
    "    \n",
    "    df_selection = df_selection.loc[mask].copy()\n",
    "    df_selection[key].hist(ax=ax, bins=bins, label='ok', alpha=0.3)\n",
    "    \n",
    "    ylims = ax.get_ylim()\n",
    "    ax.fill_between(limits, [ylims[1],ylims[1]], y2=0, color='green', alpha=0.2, label='valid')\n",
    "    ax.set_xlabel(key)\n",
    "    ax.set_title('Removed: %i' % (len(mask)-mask.sum()))\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_limits(row):\n",
    "    draught=(row['TA']+row['TF'])/2\n",
    "    OG=row['kg']-draught\n",
    "    CB=row['Disp']/(row['lpp']*row['beam']*draught)\n",
    "    \n",
    "    try:\n",
    "        si.verify_inputs(LPP=row['lpp'], Beam=row['beam'], CB=CB, CMID=row['A0'], OG=OG, PHI=1, \n",
    "                  lBK=row['BKL'], bBK=row['BKB'], OMEGA=row['omega0'], DRAFT=draught)\n",
    "    except si.SimplifiedIkedaInputError:\n",
    "        return False\n",
    "    except Exception:\n",
    "        raise\n",
    "    else:\n",
    "        return True\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df_limited.iloc[0]\n",
    "mask = df_limited.apply(func=verify_limits, axis=1)\n",
    "df_compare_zero_limits = df_limited.loc[mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "x=df_compare_zero_limits['B_e_hat']\n",
    "y=df_compare_zero_limits['B_e_hat_ikeda']\n",
    "ax.plot(x, y, 'o', alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('$\\hat{B_e}$ (model test)')\n",
    "ax.set_ylabel('$\\hat{B_e}$ (Simplified Ikeda)')\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "lim = np.max([xlim[1],ylim[1]])\n",
    "ax.set_xlim(0,lim)\n",
    "ax.set_ylim(0,lim)\n",
    "ax.plot([0,lim],[0,lim],'r-')\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "x=df_compare['B_e_hat']\n",
    "y=df_compare['B_e_hat_ikeda']\n",
    "ax.plot(x, y, 'o', alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('$\\hat{B_e}$ (model test)')\n",
    "ax.set_ylabel('$\\hat{B_e}$ (Simplified Ikeda)')\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "lim = np.max([xlim[1],ylim[1]])\n",
    "ax.set_xlim(0,lim)\n",
    "ax.set_ylim(0,lim)\n",
    "ax.plot([0,lim],[0,lim],'r-')\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax.grid(True)\n",
    "save_fig(fig=fig, name='B_e_hat_ikeda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare['error'] = (df_compare['B_e_hat']-df_compare['B_e_hat_ikeda']).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes=plt.subplots(nrows=2)\n",
    "ax=axes[0]\n",
    "df_compare.plot(x='TA', y='error', style='o', alpha=0.5,ax=ax)\n",
    "ax.set_xlabel('$T/L_{pp}$')\n",
    "ax.grid(True)\n",
    "\n",
    "ax=axes[1]\n",
    "df_compare.plot(x='omega0_hat', y='error', style='o', alpha=0.5, ax=ax)\n",
    "ax.set_xlabel('$\\hat{\\omega_0}$')\n",
    "ax.grid(True)\n",
    "save_fig(fig=fig, name='B_e_hat_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "mask=((df_compare['TA']>0.035) & (df_compare['omega0_hat']<0.63))\n",
    "df_compare_good = df_compare.loc[mask].copy()\n",
    "df_compare_good.plot(x='B_e_hat', y='B_e_hat_ikeda', ax=ax, style='o', alpha=0.5)\n",
    "ax.set_xlabel('$\\hat{B_e}$')\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "lim = np.max([xlim[1],ylim[1]])\n",
    "ax.set_xlim(0,lim)\n",
    "ax.set_ylim(0,lim)\n",
    "ax.plot([0,lim],[0,lim],'r-')\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax.grid(True)\n",
    "save_fig(fig=fig, name='B_e_hat_good')              \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_true=df_compare_good['B_e_hat'], y_pred=df_compare_good.loc[mask]['B_e_hat_ikeda'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ikeda.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_compare.copy()\n",
    "data['T'] = (data['TA']+data['TF'] )/2\n",
    "data['CB'] = data['Disp']/(data['lpp']*data['T']*data['beam'])\n",
    "data['OG'] = (-data.kg + data['T'])\n",
    "renamers = {\n",
    "    'CP' : 'C_p',\n",
    "    'CB' : 'C_b',\n",
    "    'IRUD' : 'I_RUD', \n",
    "    'BKL' : 'BK_L', \n",
    "    'gm' : 'GM', \n",
    "    'A0' : 'A_0', \n",
    "    'ship_type_id' : 'ship_type_id', \n",
    "    'Volume' : 'Disp', \n",
    "    'Ixx' : 'I_xx', \n",
    "    'BKB' : 'BK_B',\n",
    "    'KXX' : 'K_xx', \n",
    "    'RH' : 'R_h', \n",
    "    'AR' : 'A_R', \n",
    "    'TWIN' : 'TWIN', \n",
    "    'kg': 'kg', \n",
    "    'CW' : 'C_W', \n",
    "    'beam' : 'beam', \n",
    "    'TF' : 'T_F', \n",
    "    'ship_speed' : 'V', \n",
    "    'TA' : 'T_A',\n",
    "    'lpp' : 'L_pp',\n",
    "}\n",
    "data.rename(columns=renamers, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ikeda_parameters = [\n",
    "        'beam',\n",
    "        'T',\n",
    "        'BK_L',\n",
    "        'BK_B',\n",
    "        'OG',\n",
    "        'omega0_hat',        \n",
    "        'C_b',\n",
    "        'A_0',\n",
    "        'V']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[ikeda_parameters].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pure polynom ikeda parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_treshold = VarianceThreshold(0.000)\n",
    "#standard_scaler = StandardScaler()\n",
    "\n",
    "\n",
    "y = data['B_e_hat']\n",
    "X = data[ikeda_parameters]\n",
    "       \n",
    "polynomial_features = PolynomialFeatures(degree=2)\n",
    "linear_regression = LinearRegression()\n",
    "\n",
    "ks = np.arange(1,11,1)\n",
    "scores = []\n",
    "stds = []\n",
    "for k in ks:\n",
    "    select_k_best = SelectKBest(k=k, score_func=f_regression)\n",
    "    steps=[\n",
    "            ('polynomial_feature', polynomial_features),\n",
    "            #('standard_scaler', standard_scaler),\n",
    "            ('variance_treshold',variance_treshold),\n",
    "            ('select_k_best',select_k_best),\n",
    "            ('linear_regression', linear_regression)\n",
    "    ]\n",
    "    \n",
    "    model = Pipeline(steps=steps)\n",
    "    model.fit(X=X, y=y)\n",
    "    cv=5\n",
    "    score = cross_val_score(estimator=model,X=X,y=y,cv=cv).mean()\n",
    "    std = cross_val_score(estimator=model,X=X,y=y,cv=cv).std()\n",
    "    \n",
    "    scores.append(score)\n",
    "    stds.append(std)\n",
    "    \n",
    "scores = np.array(scores)\n",
    "stds = np.array(stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(ks,scores-stds,'.-')\n",
    "ax.plot(ks,scores,'.-')\n",
    "ax.plot(ks,scores+stds,'.-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_k_best = SelectKBest(k=10, score_func=f_regression)\n",
    "steps=[\n",
    "        ('polynomial_feature', polynomial_features),\n",
    "        #('standard_scaler', standard_scaler),\n",
    "        ('variance_treshold',variance_treshold),\n",
    "        ('select_k_best',select_k_best),\n",
    "        ('linear_regression', linear_regression)\n",
    "]\n",
    "\n",
    "model = Pipeline(steps=steps)\n",
    "model.fit(X=X, y=y)\n",
    "cv=5\n",
    "score = cross_val_score(estimator=model,X=X,y=y,cv=cv).mean()\n",
    "std = cross_val_score(estimator=model,X=X,y=y,cv=cv).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynom = Polynom(model=model, columns=X.columns, y_symbol=symbols.B_e_hat)\n",
    "polynom.fit(X=X, y=y)\n",
    "polynom.equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['B_e_regression_polynom'] = model.predict(X=X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "data.plot(x='B_e_hat', y=['B_e_hat_ikeda','B_e_regression_polynom'], ax=ax, style='o', alpha=0.4)\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "lim = np.max([xlim[1],ylim[1]])\n",
    "ax.set_xlim(0,lim)\n",
    "ax.set_ylim(0,lim)\n",
    "ax.plot([0,lim],[0,lim],'r-')\n",
    "ax.set_aspect('equal', 'box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "mask = ((data['B_e_regression_polynom'] < 0.0029) & \n",
    "        (data['B_e_regression_polynom'] > 0.0026))\n",
    "df_strange=data.loc[mask].copy()\n",
    "df_strange.loc[mask].plot(x='B_e_hat', y=['B_e_regression_polynom'], ax=ax, style='o', alpha=0.4)\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "lim = np.max([xlim[1],ylim[1]])\n",
    "ax.set_xlim(0,lim)\n",
    "ax.set_ylim(0,lim)\n",
    "ax.plot([0,lim],[0,lim],'r-')\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_strange.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_strange['T'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_strange['omega0_hat'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_strange['V'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ((data['V'].round(decimals=2)==0) )\n",
    "data_zero = data.loc[mask].copy()\n",
    "data_zero['error'] = data_zero['B_e_hat']-data_zero['B_e_hat_ikeda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "data_zero.plot(x='B_e_hat', y=['B_e_hat_ikeda'], ax=ax, style='o', alpha=0.4)\n",
    "ax.set_xlabel('$\\hat{B_e}$')\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "lim = np.max([xlim[1],ylim[1]])\n",
    "ax.set_xlim(0,lim)\n",
    "ax.set_ylim(0,lim)\n",
    "ax.plot([0,lim],[0,lim],'r-')\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax.grid()\n",
    "save_fig(fig=fig, name='B_e_hat_ikeda_zero')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_zero.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_zero.plot(x='T', y='error', style='o', alpha=0.4)\n",
    "data_zero.plot(x='error', y=['B_W_HAT','B_E_HAT','B_F_HAT','B_BK_HAT'], style='o', alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_true=data_zero['B_e_hat'], y_pred=data_zero['B_e_hat_ikeda'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_zero['B_e_hat_ikeda2'] = data_zero['B_e_hat_ikeda']-data_zero['B_W_HAT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_true=data_zero['B_e_hat'], y_pred=data_zero['B_e_hat_ikeda2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "data_zero.plot(x='B_e_hat', y=['B_e_hat_ikeda2'], ax=ax, style='o', alpha=0.4)\n",
    "ax.set_xlabel('$\\hat{B_e}$')\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "lim = np.max([xlim[1],ylim[1]])\n",
    "ax.set_xlim(0,lim)\n",
    "ax.set_ylim(0,lim)\n",
    "ax.plot([0,lim],[0,lim],'r-')\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_parameters = [\n",
    "'C_p',\n",
    "'C_b',\n",
    "'I_RUD', \n",
    "'BK_L', \n",
    "'GM', \n",
    "'A_0',  \n",
    "'K_xx', \n",
    "'A_R', \n",
    "'TWIN', \n",
    "'kg', \n",
    "'C_W', \n",
    "'beam', \n",
    "]\n",
    "\n",
    "#parameters = list(set(ikeda_parameters) | set(additional_parameters) | set(['B_F_HAT']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = list(set(ikeda_parameters) | set(additional_parameters) )\n",
    "\n",
    "variance_treshold = VarianceThreshold(0.000)\n",
    "\n",
    "y_key='B_e_hat'\n",
    "data_=data_zero[parameters+[y_key]].copy()\n",
    "data_.dropna(inplace=True)\n",
    "y = data_[y_key]\n",
    "X = data_[parameters].copy()\n",
    "       \n",
    "polynomial_features = PolynomialFeatures(degree=1)\n",
    "linear_regression = LinearRegression()\n",
    "\n",
    "ks = np.arange(1,17,1)\n",
    "scores = []\n",
    "stds = []\n",
    "for k in ks:\n",
    "    select_k_best = SelectKBest(k=k, score_func=f_regression)\n",
    "    steps=[\n",
    "            ('polynomial_feature', polynomial_features),\n",
    "            ('variance_treshold',variance_treshold),\n",
    "            ('select_k_best',select_k_best),\n",
    "            ('linear_regression', linear_regression)\n",
    "    ]\n",
    "    \n",
    "    model = Pipeline(steps=steps)\n",
    "    model.fit(X=X, y=y)\n",
    "    cv=5\n",
    "    score = cross_val_score(estimator=model,X=X,y=y,cv=cv).mean()\n",
    "    std = cross_val_score(estimator=model,X=X,y=y,cv=cv).std()\n",
    "    \n",
    "    scores.append(score)\n",
    "    stds.append(std)\n",
    "    \n",
    "scores = np.array(scores)\n",
    "stds = np.array(stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(ks,scores-stds,'.-')\n",
    "ax.plot(ks,scores,'.-')\n",
    "ax.plot(ks,scores+stds,'.-')\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.argmax(scores)\n",
    "k=ks[index]\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_k_best = SelectKBest(k=5, score_func=f_regression)\n",
    "steps=[\n",
    "        ('polynomial_feature', polynomial_features),\n",
    "        #('standard_scaler', standard_scaler),\n",
    "        ('variance_treshold',variance_treshold),\n",
    "        ('select_k_best',select_k_best),\n",
    "        ('linear_regression', linear_regression)\n",
    "]\n",
    "\n",
    "model_zero = Pipeline(steps=steps)\n",
    "model_zero.fit(X=X, y=y)\n",
    "cv=5\n",
    "score = cross_val_score(estimator=model_zero,X=X,y=y,cv=cv).mean()\n",
    "std = cross_val_score(estimator=model_zero,X=X,y=y,cv=cv).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynom_zero = Polynom(model=model_zero, columns=X.columns, y_symbol=symbols.B_e_hat)\n",
    "polynom_zero.fit(X=X, y=y)\n",
    "polynom_zero.equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynom_zero.score(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_['B_e_hat_regression'] = polynom_zero.predict(data_[parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "data_.plot(x='B_e_hat', y=['B_e_hat_regression'], ax=ax, style='o', alpha=0.4)\n",
    "ax.set_xlabel('$\\hat{B_e}$')\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "lim = np.max([xlim[1],ylim[1]])\n",
    "ax.set_xlim(0,lim)\n",
    "ax.set_ylim(0,lim)\n",
    "ax.plot([0,lim],[0,lim],'r-')\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax.grid()\n",
    "\n",
    "save_fig(fig=fig, name='B_e_hat0_regression')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['B_e_hat0']=polynom_zero.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=data['V'].round(decimals=2)>0\n",
    "data_speed=data.loc[mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_speed['B_e_hat0'].hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_speed['speed_factor']=data_speed['B_e_hat']/(data_speed['B_e_hat0']*data_speed['V'])\n",
    "data_speed['speed_factor']=data_speed['B_e_hat']/data_speed['B_e_hat0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_speed['speed_factor'].hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data_speed['speed_factor'] < data_speed['speed_factor'].quantile(0.90)\n",
    "data_speed=data_speed.loc[mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_speed['speed_factor'].hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = list(set(ikeda_parameters) | set(additional_parameters) | set(['B_L_HAT']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_treshold = VarianceThreshold(0.000)\n",
    "\n",
    "y_key='speed_factor'\n",
    "data_=data_speed[parameters+[y_key]].copy()\n",
    "data_.dropna(inplace=True)\n",
    "y = data_[y_key]\n",
    "X = data_[parameters].copy()\n",
    "       \n",
    "polynomial_features = PolynomialFeatures(degree=1)\n",
    "linear_regression = LinearRegression()\n",
    "\n",
    "ks = np.arange(1,6,1)\n",
    "scores = []\n",
    "stds = []\n",
    "for k in ks:\n",
    "    select_k_best = SelectKBest(k=k, score_func=f_regression)\n",
    "    steps=[\n",
    "            ('polynomial_feature', polynomial_features),\n",
    "            ('variance_treshold',variance_treshold),\n",
    "            ('select_k_best',select_k_best),\n",
    "            ('linear_regression', linear_regression)\n",
    "    ]\n",
    "    \n",
    "    model = Pipeline(steps=steps)\n",
    "    model.fit(X=X, y=y)\n",
    "    cv=5\n",
    "    score = cross_val_score(estimator=model,X=X,y=y,cv=cv).mean()\n",
    "    std = cross_val_score(estimator=model,X=X,y=y,cv=cv).std()\n",
    "    \n",
    "    scores.append(score)\n",
    "    stds.append(std)\n",
    "    \n",
    "scores = np.array(scores)\n",
    "stds = np.array(stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(ks,scores-stds,'.-')\n",
    "ax.plot(ks,scores,'.-')\n",
    "ax.plot(ks,scores+stds,'.-')\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_k_best = SelectKBest(k=5, score_func=f_regression)\n",
    "steps=[\n",
    "        ('polynomial_feature', polynomial_features),\n",
    "        #('standard_scaler', standard_scaler),\n",
    "        ('variance_treshold',variance_treshold),\n",
    "        ('select_k_best',select_k_best),\n",
    "        ('linear_regression', linear_regression)\n",
    "]\n",
    "\n",
    "model_speed = Pipeline(steps=steps)\n",
    "model_speed.fit(X=X, y=y)\n",
    "cv=5\n",
    "score = cross_val_score(estimator=model_speed,X=X,y=y,cv=cv).mean()\n",
    "std = cross_val_score(estimator=model_speed,X=X,y=y,cv=cv).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynom_speed = Polynom(model=model_speed, columns=X.columns, y_symbol=symbols.B_e_hat)\n",
    "polynom_speed.fit(X=X, y=y)\n",
    "polynom_speed.equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_speed['speed_factor_regression'] = polynom_speed.predict(data_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "data_speed.plot(x='speed_factor', y=['speed_factor_regression'], ax=ax, style='o', alpha=0.4)\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "lim = np.max([xlim[1],ylim[1]])\n",
    "ax.set_xlim(0,lim)\n",
    "ax.set_ylim(0,lim)\n",
    "ax.plot([0,lim],[0,lim],'r-')\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax.grid()\n",
    "save_fig(fig=fig, name='B_e_factor_regression')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['speed_factor_regression'] = polynom_speed.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['B_e_hat_speed_regression']=data['B_e_hat0']*data['speed_factor_regression'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['B_e_hat_speed_regression','B_e_hat0','speed_factor_regression','V','B_L_HAT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['error'] = data['B_e_hat'] - data['B_e_hat_speed_regression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes=plt.subplots(ncols=2)\n",
    "ax=axes[0]\n",
    "data.plot(x='B_e_hat', y=['B_e_hat_speed_regression'], ax=ax, style='o', alpha=0.4)\n",
    "ax.set_xlabel('$\\hat{B_e}$')\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "lim = np.max([xlim[1],ylim[1]])\n",
    "ax.set_xlim(0,lim)\n",
    "ax.set_ylim(0,lim)\n",
    "ax.plot([0,lim],[0,lim],'r-')\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax.grid()\n",
    "\n",
    "\n",
    "ax=axes[1]\n",
    "data.plot(x='T', y=['error'], ax=ax, style='o', alpha=0.4)\n",
    "ax.set_xlabel('$T/L_{pp}$')\n",
    "ax.grid()\n",
    "\n",
    "save_fig(fig=fig, name='B_e_factor_regression_total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data['B_e_hat_speed_regression'].notnull()\n",
    "data_ = data.loc[mask].copy()\n",
    "\n",
    "r2_score(y_true=data_['B_e_hat'], y_pred=data_['B_e_hat_speed_regression'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_true=data_['B_e_hat'], y_pred=data_['B_e_hat_ikeda'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speed_and_no_speed = data.groupby(by='loading_condition_id').filter(lambda x: (((x['V'].round(decimals=2)==0).sum()>0) &\n",
    "                                                          ((x['V'].round(decimals=2)!=0).sum()>0))\n",
    "                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for model_number, group_model in df_speed_and_no_speed.groupby(by=['model_number']):\n",
    "    fig,ax=plt.subplots()\n",
    "    for loading_condition_id, group_loading_condition in group_model.groupby(by=['loading_condition_id']):\n",
    "        group_loading_condition.sort_values(by='V', inplace=True)\n",
    "        group_loading_condition.plot(x='V', y='B_e_hat', ax=ax, style='.-')\n",
    "    \n",
    "    ax.set_xlim(df_speed_and_no_speed['V'].min(), df_speed_and_no_speed['V'].max())\n",
    "    ax.set_ylim(df_speed_and_no_speed['B_e_hat'].min(), df_speed_and_no_speed['B_e_hat'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_split(df_speed_and_no_speed, test_part = 0.20):\n",
    "    df_speed_and_no_speed=df_speed_and_no_speed.copy()    \n",
    "    \n",
    "    model_groups = df_speed_and_no_speed.groupby(by='model_number')\n",
    "    \n",
    "    number_of_tests=int(len(model_groups)*test_part)\n",
    "    random_index = np.random.permutation(len(model_groups))[0:number_of_tests]\n",
    "    test_model_numbers = np.array(list(model_groups.groups.keys()))[random_index]\n",
    "    \n",
    "    data_test = model_groups.filter(lambda x:x.iloc[0]['model_number'] in test_model_numbers)\n",
    "    \n",
    "    index_train = list(set(data.index) - set(data_test.index))\n",
    "    data_train=data.loc[index_train].copy()\n",
    "    \n",
    "    return data_train,data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train,data_test = test_split(df_speed_and_no_speed=df_speed_and_no_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(data):\n",
    "    \n",
    "    data=data.copy()\n",
    "    polynom_zero= fit_zero(data)\n",
    "    data['B_e_hat0']=polynom_zero.predict(data)\n",
    "    \n",
    "    mask = data['V'].round(decimals=2)>0\n",
    "    data_speed = data.loc[mask].copy()\n",
    "    data_speed['speed_factor']=data_speed['B_e_hat']/data_speed['B_e_hat0']\n",
    "    \n",
    "    polynom_speed = fit_speed_factor(data_speed)\n",
    "    data['speed_factor_regression']=polynom_speed.predict(data) \n",
    "    \n",
    "    return polynom_zero,polynom_speed\n",
    "\n",
    "\n",
    "def fit_zero(data):\n",
    "    \n",
    "    mask = ((data['V'].round(decimals=2)==0) )\n",
    "    data_zero = data.loc[mask].copy()\n",
    "    parameters = list(set(ikeda_parameters) | set(additional_parameters) )\n",
    "    \n",
    "    y_key='B_e_hat'\n",
    "    data_=data_zero[parameters+[y_key]].copy()\n",
    "    data_.dropna(inplace=True)\n",
    "    y = data_[y_key]\n",
    "    X = data_[parameters].copy()\n",
    "    \n",
    "    select_k_best = SelectKBest(k=5, score_func=f_regression)\n",
    "    steps=[\n",
    "            ('polynomial_feature', polynomial_features),\n",
    "            #('standard_scaler', standard_scaler),\n",
    "            ('variance_treshold',variance_treshold),\n",
    "            ('select_k_best',select_k_best),\n",
    "            ('linear_regression', linear_regression)\n",
    "    ]\n",
    "    \n",
    "    model_zero = Pipeline(steps=steps)\n",
    "    model_zero.fit(X=X, y=y)\n",
    "    \n",
    "    polynom_zero = Polynom(model=model_zero, columns=X.columns, y_symbol=symbols.B_e_hat_0)\n",
    "    polynom_zero.fit(X=X, y=y)\n",
    "    \n",
    "    return polynom_zero\n",
    "\n",
    "def fit_speed_factor(data):\n",
    "    \n",
    "    parameters = list(set(ikeda_parameters) | set(additional_parameters) | set(['B_L_HAT']))\n",
    "    \n",
    "    y_key='speed_factor'\n",
    "    data_=data_speed[parameters+[y_key]].copy()\n",
    "    data_.dropna(inplace=True)\n",
    "    y = data_[y_key]\n",
    "    X = data_[parameters].copy()\n",
    "    \n",
    "    select_k_best = SelectKBest(k=5, score_func=f_regression)\n",
    "    steps=[\n",
    "        ('polynomial_feature', polynomial_features),\n",
    "        #('standard_scaler', standard_scaler),\n",
    "        ('variance_treshold',variance_treshold),\n",
    "        ('select_k_best',select_k_best),\n",
    "        ('linear_regression', linear_regression)\n",
    "    ]\n",
    "\n",
    "    model_speed = Pipeline(steps=steps)\n",
    "    model_speed.fit(X=X, y=y)\n",
    "    polynom_speed = Polynom(model=model_speed, columns=X.columns, y_symbol=symbols.B_e_factor)\n",
    "    polynom_speed.fit(X=X, y=y)\n",
    "    polynom_speed.equation\n",
    "    \n",
    "    return polynom_speed\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynom_zero,polynom_speed = fit(data)\n",
    "y_pred=polynom_zero.predict(data)*polynom_speed.predict(data)\n",
    "r2_score(y_true=data['B_e_hat'], y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='polynom_zero'\n",
    "equation = significant_numbers(polynom_zero.equation, precision=3)\n",
    "eq=pylatex_extenders.Equation(equation,label='eq:%s'%name)\n",
    "file_path = os.path.join(rolldecay.equations_path,name)\n",
    "eq.generate_tex(file_path)\n",
    "\n",
    "name='polynom_speed'\n",
    "equation = significant_numbers(polynom_speed.equation, precision=3)\n",
    "eq=pylatex_extenders.Equation(equation,label='eq:%s'%name)\n",
    "file_path = os.path.join(rolldecay.equations_path,name)\n",
    "eq.generate_tex(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynom_zero,polynom_speed = fit(data_train)\n",
    "y_pred=polynom_zero.predict(data_test)*polynom_speed.predict(data_test)\n",
    "mask=y_pred.notnull()\n",
    "r2_score(y_true=data_test.loc[mask]['B_e_hat'], y_pred=y_pred.loc[mask])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in range(100):\n",
    "    data_train,data_test = test_split(df_speed_and_no_speed=df_speed_and_no_speed)\n",
    "    polynom_zero,polynom_speed = fit(data_train)\n",
    "    y_pred=polynom_zero.predict(data_test)*polynom_speed.predict(data_test)\n",
    "    mask=y_pred.notnull()\n",
    "    score = r2_score(y_true=data_test.loc[mask]['B_e_hat'], y_pred=y_pred.loc[mask])\n",
    "    scores.append(score)\n",
    "    \n",
    "scores=np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ((np.quantile(scores, 0.10) < scores) & (scores< np.quantile(scores, 0.90)))\n",
    "scores=scores[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
