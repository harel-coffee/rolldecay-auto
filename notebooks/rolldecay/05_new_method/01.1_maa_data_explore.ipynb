{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roll damping data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15, 5\n",
    "\n",
    "import data\n",
    "import copy\n",
    "from mdldb.mdl_db import MDLDataBase\n",
    "from mdldb.tables import Base, Model, LoadingCondition, Run, RolldecayLinear, RolldecayDirect, RolldecayNorwegian\n",
    "from mdldb.tables import Min, Mean, Max, Std, Ship\n",
    "from mdldb import mdl_to_evaluation\n",
    "from evaluation.run_dynamic import RunDynamic\n",
    "from evaluation.run_manoeuvring import RunZigZag\n",
    "from rolldecay.bis_system import BisSystem\n",
    "\n",
    "from rolldecayestimators.direct_estimator import DirectEstimator\n",
    "from rolldecayestimators.direct_linear_estimator import DirectLinearEstimator\n",
    "from rolldecayestimators.norwegian_estimator import NorwegianEstimator\n",
    "from rolldecayestimators.transformers import CutTransformer, LowpassFilterDerivatorTransformer, ScaleFactorTransformer, OffsetTransformer\n",
    "#from rolldecay.equations_lambdify import calculate_acceleration, calculate_velocity\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import signal_lab\n",
    "from sqlalchemy.inspection import inspect\n",
    "import seaborn as sns\n",
    "import docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///' + data.mdl_db_path)\n",
    "db = MDLDataBase(engine=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=\"\"\"\n",
    "SELECT * from\n",
    "rolldecay_direct_improved\n",
    "INNER JOIN run\n",
    "ON rolldecay_direct_improved.run_id == run.id\n",
    "    INNER JOIN loading_conditions\n",
    "    ON (run.loading_condition_id == loading_conditions.id)\n",
    "        INNER JOIN models\n",
    "        ON run.model_number == models.model_number\n",
    "            INNER JOIN ships\n",
    "            ON models.ship_name == ships.name\n",
    "\n",
    "\"\"\"\n",
    "df_rolldecay = pd.read_sql(sql, con=engine, index_col='run_id',)\n",
    "df_rolldecay = df_rolldecay.loc[:,~df_rolldecay.columns.duplicated()]\n",
    "#df_rolldecay = remove_outliers(df_rolldecay)\n",
    "df_rolldecay.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rolldecay.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = pd.read_sql_table('description', con=db.engine, index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_rolldecay.dropna(subset=['omega0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['score'] > 0.95\n",
    "df = df.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='ship_speed', inplace=True)\n",
    "for model_number, model_group in df.groupby(by='model_number'):\n",
    "    \n",
    "    fig,ax=plt.subplots()\n",
    "    fig.set_dpi(50)\n",
    "    fig.set_size_inches(10,5)\n",
    "    model_group.plot(x='ship_speed', y='mean_damping', style='o-', ax=ax)\n",
    "    ax.set_title(model_number)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()\n",
    "units = description.loc[data.columns]['unit']\n",
    "data['ship_speed']*=1.852/3.6\n",
    "units['ship_speed']=r'm/s'\n",
    "\n",
    "data['g']=9.81\n",
    "data['rho']=1000\n",
    "units['g']=r'm/s**2'\n",
    "units['rho']=r'kg/m**3'\n",
    "\n",
    "data['omega0_hat'] = data['omega0']*np.sqrt(data['beam']/(2*data['g']))\n",
    "units['omega0_hat'] = '-'\n",
    "\n",
    "bis_system = BisSystem(lpp=data['lpp'], volume=data['Volume'], units=units)\n",
    "data = bis_system.df_to_bis(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist('score', bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist('omega0', bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist('omega0_hat', bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist('zeta', bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist('d', bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist('mean_damping', bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop(columns=['zeta','d','omega0','mean_damping'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_treshold = VarianceThreshold(0.001)\n",
    "X_ = variance_treshold.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = variance_treshold.fit_transform(X)\n",
    "X_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[variance_treshold.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GM = data['gm']\n",
    "rxx = data['KXX']\n",
    "kxx = rxx/data['beam']\n",
    "rho = data['rho']\n",
    "m = rho*data['Volume']\n",
    "Ixx = m*rxx**2\n",
    "data['Ixx']=Ixx\n",
    "if not 'Ixx' in important:\n",
    "    important.append('Ixx')\n",
    "g = data['g']\n",
    "omega0 = data['omega0']\n",
    "data['Ixx_tot'] = Ixx_tot = GM*g*m/(omega0**2)\n",
    "data['Ixx_added'] = Ixx_added = Ixx_tot - Ixx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data['Ixx_added']>0\n",
    "data = data.loc[mask].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Omega0 regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_key = 'omega0_hat'\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "data[y_key].hist(bins=50, ax=ax)\n",
    "ax.set_title('Historgram: %s' % y_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = np.arange(1,10)\n",
    "degrees = np.arange(1,3)\n",
    "results = pd.DataFrame()\n",
    "\n",
    "variance_treshold = VarianceThreshold(0.0001)\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "y = data[y_key]\n",
    "X = data[important]\n",
    "\n",
    "for k in ks:\n",
    "    for degree in degrees:\n",
    "        select_k_best = SelectKBest(k=k, score_func=f_regression)\n",
    "        \n",
    "       \n",
    "        polynomial_features = PolynomialFeatures(degree=degree)\n",
    "        linear_regression = LinearRegression()\n",
    "        \n",
    "        steps=[\n",
    "            ('polynomial_feature', polynomial_features),\n",
    "            ('standard_scaler', standard_scaler),\n",
    "            ('variance_treshold',variance_treshold),\n",
    "            ('select_k_best',select_k_best),\n",
    "            ('linear_regression', linear_regression)\n",
    "        ]\n",
    "        \n",
    "        model = Pipeline(steps=steps)\n",
    "        score = cross_val_score(estimator=model,X=X,y=y,cv=5).mean()\n",
    "        s = pd.Series()\n",
    "        s['k'] = k\n",
    "        s['degree'] = degree\n",
    "        s['score'] = score\n",
    "        results = results.append(s, ignore_index=True)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(by='score', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = int(results.iloc[0]['k'])\n",
    "degree = int(results.iloc[0]['degree'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_k_best = SelectKBest(k=k, score_func=f_regression)\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "polynomial_features = PolynomialFeatures(degree=degree)\n",
    "linear_regression = LinearRegression()\n",
    "\n",
    "steps=[\n",
    "    ('polynomial_feature', polynomial_features),\n",
    "    ('standard_scaler', standard_scaler),\n",
    "    ('variance_treshold',variance_treshold),\n",
    "    ('select_k_best',select_k_best),\n",
    "    ('linear_regression', linear_regression)\n",
    "]\n",
    "\n",
    "model = Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "model.fit(X=X_train, y=y_train)\n",
    "score = model.score(X=X_test, y=y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(y_test,model.predict(X_test),'.', alpha=0.5)\n",
    "ax.set_title('Prediction of %s' % y_key)\n",
    "ax.set_xlabel('test: %s' % y_key)\n",
    "ax.set_ylabel('predicted: %s' % y_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## damping regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data['ship_speed']==0\n",
    "data_0 = data.loc[mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_key = 'mean_damping'\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "data_0[y_key].hist(bins=50, ax=ax)\n",
    "ax.set_title('Historgram: %s' % y_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = np.arange(1,10)\n",
    "degrees = np.arange(1,3)\n",
    "results = pd.DataFrame()\n",
    "\n",
    "variance_treshold = VarianceThreshold(0.0001)\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "y = data_0[y_key]\n",
    "X2 = data_0[important]\n",
    "\n",
    "for k in ks:\n",
    "    for degree in degrees:\n",
    "        select_k_best = SelectKBest(k=k, score_func=f_regression)\n",
    "        \n",
    "       \n",
    "        polynomial_features = PolynomialFeatures(degree=degree)\n",
    "        linear_regression = LinearRegression()\n",
    "        \n",
    "        steps=[\n",
    "            ('polynomial_feature', polynomial_features),\n",
    "            ('standard_scaler', standard_scaler),\n",
    "            ('variance_treshold',variance_treshold),\n",
    "            ('select_k_best',select_k_best),\n",
    "            ('linear_regression', linear_regression)\n",
    "        ]\n",
    "        \n",
    "        model = Pipeline(steps=steps)\n",
    "        score = cross_val_score(estimator=model,X=X2,y=y,cv=3).mean()\n",
    "        s = pd.Series()\n",
    "        s['k'] = k\n",
    "        s['degree'] = degree\n",
    "        s['score'] = score\n",
    "        results = results.append(s, ignore_index=True)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(by='score', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = int(results.iloc[0]['k'])\n",
    "degree = int(results.iloc[0]['degree'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_k_best = SelectKBest(k=k, score_func=f_regression)\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "polynomial_features = PolynomialFeatures(degree=degree)\n",
    "linear_regression = LinearRegression()\n",
    "\n",
    "steps=[\n",
    "    ('polynomial_feature', polynomial_features),\n",
    "    ('standard_scaler', standard_scaler),\n",
    "    ('variance_treshold',variance_treshold),\n",
    "    ('select_k_best',select_k_best),\n",
    "    ('linear_regression', linear_regression)\n",
    "]\n",
    "\n",
    "model = Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X2, y, test_size=0.33)\n",
    "model.fit(X=X_train, y=y_train)\n",
    "score = model.score(X=X_test, y=y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(y_test,model.predict(X_test),'.', alpha=0.5)\n",
    "ax.set_title('Prediction of %s' % y_key)\n",
    "ax.set_xlabel('test: %s' % y_key)\n",
    "ax.set_ylabel('predicted: %s' % y_key)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
