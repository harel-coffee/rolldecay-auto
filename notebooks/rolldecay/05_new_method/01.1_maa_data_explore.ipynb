{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roll damping data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_colwidth = 100\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15, 5\n",
    "\n",
    "import data\n",
    "import copy\n",
    "from mdldb.mdl_db import MDLDataBase\n",
    "from mdldb.tables import Base, Model, LoadingCondition, Run, RolldecayLinear, RolldecayDirect, RolldecayNorwegian\n",
    "from mdldb.tables import Min, Mean, Max, Std, Ship\n",
    "from mdldb import mdl_to_evaluation\n",
    "from evaluation.run_dynamic import RunDynamic\n",
    "from evaluation.run_manoeuvring import RunZigZag\n",
    "from rolldecay.bis_system import BisSystem\n",
    "\n",
    "from rolldecayestimators.direct_estimator import DirectEstimator\n",
    "from rolldecayestimators.direct_linear_estimator import DirectLinearEstimator\n",
    "from rolldecayestimators.norwegian_estimator import NorwegianEstimator\n",
    "from rolldecayestimators.transformers import CutTransformer, LowpassFilterDerivatorTransformer, ScaleFactorTransformer, OffsetTransformer\n",
    "#from rolldecay.equations_lambdify import calculate_acceleration, calculate_velocity\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import signal_lab\n",
    "from sqlalchemy.inspection import inspect\n",
    "import seaborn as sns\n",
    "import docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///' + data.mdl_db_path)\n",
    "db = MDLDataBase(engine=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=\"\"\"\n",
    "SELECT * from\n",
    "rolldecay_direct_improved\n",
    "INNER JOIN run\n",
    "ON rolldecay_direct_improved.run_id == run.id\n",
    "    INNER JOIN projects\n",
    "    ON (run.project_number == projects.project_number)\n",
    "        INNER JOIN loading_conditions\n",
    "        ON (run.loading_condition_id == loading_conditions.id)\n",
    "            INNER JOIN models\n",
    "            ON run.model_number == models.model_number\n",
    "                INNER JOIN ships\n",
    "                ON models.ship_name == ships.name\n",
    "\n",
    "\"\"\"\n",
    "df_rolldecay = pd.read_sql(sql, con=engine, index_col='run_id',)\n",
    "df_rolldecay = df_rolldecay.loc[:,~df_rolldecay.columns.duplicated()]\n",
    "#df_rolldecay = remove_outliers(df_rolldecay)\n",
    "df_rolldecay.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rolldecay.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = pd.read_sql_table('description', con=db.engine, index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_rolldecay.dropna(subset=['omega0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['score'] > 0.95\n",
    "df = df.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.sort_values(by='ship_speed', inplace=True)\n",
    "#for model_number, model_group in df.groupby(by='model_number'):\n",
    "#    \n",
    "#    fig,ax=plt.subplots()\n",
    "#    fig.set_dpi(50)\n",
    "#    fig.set_size_inches(10,5)\n",
    "#    model_group.plot(x='ship_speed', y='mean_damping', style='o-', ax=ax)\n",
    "#    ax.set_title(model_number)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=df[['Volume']].notnull().all(axis=1)\n",
    "df2 = df.loc[mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['BKL'].fillna(0, inplace=True)\n",
    "df2['BKB'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.sort_values(by='ship_speed', inplace=True)\n",
    "by = ['BKL','BKB']\n",
    "y = 'mean_damping'\n",
    "for model_number, model_group in df2.groupby(by=['model_number']):\n",
    "    \n",
    "    if len(model_group)==1:\n",
    "        continue  # Don't do a plot with only one point\n",
    "    \n",
    "    bk_groups = model_group.groupby(by=by)\n",
    "    \n",
    "    fig,axes=plt.subplots(ncols=len(bk_groups))\n",
    "    fig.set_dpi(100)\n",
    "    fig.set_size_inches(15,5)\n",
    "    \n",
    "    if len(bk_groups)==1:\n",
    "        axes=[axes]\n",
    "    \n",
    "    for ax,(index, bk_group) in zip(axes,bk_groups):\n",
    "    \n",
    "        title = '%s' % model_number\n",
    "        for key,value in zip(by,index):\n",
    "            title+=' %s:%0.1f' % (key,value)\n",
    "        \n",
    "        ax.set_title(title)\n",
    "        ax.set_ylim(0,df2[y].max())\n",
    "        ax.set_ylabel(y)\n",
    "        \n",
    "        bk_group.sort_values(by=['TA','ship_speed'], inplace=True)\n",
    "        for loading_condition_id, df_loading_condition in bk_group.groupby(by='loading_condition_id'):\n",
    "            row = df_loading_condition.iloc[0]\n",
    "            label = 'ta:%0.1f, tf:%0.1f' % (row['TA'],row['TF'])\n",
    "            df_loading_condition.plot(x='ship_speed', y=y, style='o-', label=label, ax=ax)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df2.groupby(by='model_number').get_group('3416-A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_model.iloc[0]['project_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This model illustrates that there can be many \"false\" runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.set_index(['loading_condition_id','ship_speed']).sort_values(by=['loading_condition_id','ship_speed','date','run_number',], \n",
    "                                                                      ascending=False)[['series_number','run_number','TA','TF','kg','gm','comment','date']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing \"false\" runs by assuming that the latest is correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest(group):\n",
    "    s = group.sort_values(by=['date','run_number'], ascending=False).iloc[0]\n",
    "    s['run_id'] = s.name\n",
    "    return s\n",
    "\n",
    "\n",
    "df_latest = df_model.groupby(by=['loading_condition_id','ship_speed']).apply(func=get_latest)\n",
    "df_latest[['date','series_number','run_number','comment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.groupby(by=['model_number','loading_condition_id','ship_speed']).apply(func=get_latest)\n",
    "df3.drop(columns=['model_number','loading_condition_id','ship_speed'], inplace=True)\n",
    "df3.reset_index(inplace=True)\n",
    "df3.set_index('run_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.sort_values(by='ship_speed', inplace=True)\n",
    "by = ['BKL','BKB']\n",
    "y = 'mean_damping'\n",
    "for model_number, model_group in df3.groupby(by=['model_number']):\n",
    "    \n",
    "    if len(model_group)==1:\n",
    "        continue  # Don't do a plot with only one point\n",
    "    \n",
    "    bk_groups = model_group.groupby(by=by)\n",
    "    \n",
    "    fig,axes=plt.subplots(ncols=len(bk_groups))\n",
    "    fig.set_dpi(100)\n",
    "    fig.set_size_inches(15,5)\n",
    "    \n",
    "    if len(bk_groups)==1:\n",
    "        axes=[axes]\n",
    "    \n",
    "    for ax,(index, bk_group) in zip(axes,bk_groups):\n",
    "    \n",
    "        title = '%s' % model_number\n",
    "        for key,value in zip(by,index):\n",
    "            title+=' %s:%0.1f' % (key,value)\n",
    "        \n",
    "        ax.set_title(title)\n",
    "        ax.set_ylim(0,df3[y].max())\n",
    "        ax.set_ylabel(y)\n",
    "        \n",
    "        bk_group.sort_values(by=['TA','ship_speed'], inplace=True)\n",
    "        for loading_condition_id, df_loading_condition in bk_group.groupby(by='loading_condition_id'):\n",
    "            row = df_loading_condition.iloc[0]\n",
    "            label = 'ta:%0.1f, tf:%0.1f' % (row['TA'],row['TF'])\n",
    "            df_loading_condition.plot(x='ship_speed', y=y, style='o-', label=label, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
