{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ikeda for many ships\n",
    "The method developed in: ([01.03_ikeda_many_dev](06_ikeda/01.03_ikeda_many_dev.ipynb)) will now be attempted for many ships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../../imports.py\n",
    "\"\"\"\n",
    "These is the standard setup for the notebooks.\n",
    "\"\"\"\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style(theme='onedork', context='notebook', ticks=True, grid=False)\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.style.use('paper')\n",
    "\n",
    "#import data\n",
    "import copy\n",
    "from rolldecay.bis_system import BisSystem\n",
    "from rolldecay import database\n",
    "from mdldb.tables import Run\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from rolldecayestimators.transformers import CutTransformer, LowpassFilterDerivatorTransformer, ScaleFactorTransformer, OffsetTransformer\n",
    "from rolldecayestimators.direct_estimator_cubic import EstimatorQuadraticB, EstimatorCubic\n",
    "from rolldecayestimators.ikeda_estimator import IkedaQuadraticEstimator\n",
    "import rolldecayestimators.equations as equations\n",
    "import rolldecayestimators.lambdas as lambdas\n",
    "from rolldecayestimators.substitute_dynamic_symbols import lambdify\n",
    "import rolldecayestimators.symbols as symbols\n",
    "import sympy as sp\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyscores2.indata import Indata\n",
    "from pyscores2.runScores2 import Calculation\n",
    "from pyscores2.output import OutputFile\n",
    "from pyscores2 import TDPError\n",
    "import pyscores2\n",
    "from rolldecayestimators.ikeda import Ikeda, IkedaR\n",
    "from rolldecayestimators.simplified_ikeda_class import SimplifiedIkeda\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_sections_id = pd.read_csv('all_sections.csv', sep=';')\n",
    "df_all_sections_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_groups=df_all_sections_id.groupby(by='loading_condition_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loading_condition_ids = df_all_sections_id['loading_condition_id'].unique()\n",
    "mask=pd.notnull(loading_condition_ids)\n",
    "loading_condition_ids=loading_condition_ids[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rolldecay = database.load(rolldecay_table_name='rolldecay_quadratic_b', limit_score=0.99, \n",
    "                             exclude_table_name='rolldecay_exclude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=df_rolldecay['loading_condition_id'].isin(loading_condition_ids)\n",
    "df=df_rolldecay.loc[mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cScores(sections):\n",
    "    sections=sections.copy()\n",
    "    sections['cScores']=sections['area']/(sections['b']*sections['t'])\n",
    "    mask=sections['cScores']>1\n",
    "    sections.loc[mask,'cScores']=1\n",
    "    return sections\n",
    "\n",
    "def cut_sections(sections, draught):\n",
    "    sections=sections.copy()\n",
    "    mask = sections['t']>draught\n",
    "    sections.loc[mask,'t']=draught\n",
    "    sections.loc[mask,'area']-=draught*sections['b'].max()  # Assuming rectangular shape\n",
    "    return sections\n",
    "\n",
    "def remove_duplicate_sections(sections):\n",
    "    sections=sections.copy()\n",
    "    mask=~sections['x'].duplicated()\n",
    "    sections=sections.loc[mask]\n",
    "    assert sections['x'].is_unique\n",
    "    return sections\n",
    "\n",
    "def too_small_sections(sections):\n",
    "    sections=sections.copy()\n",
    "    small = 0.1\n",
    "    mask=sections['b']==0\n",
    "    sections.loc[mask,'b']=small\n",
    "    mask=sections['t']==0\n",
    "    sections.loc[mask,'t']=small\n",
    "    mask=sections['area']==0\n",
    "    sections.loc[mask,'area']=small\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import simps\n",
    "def calculate_lcb(x, area, **kwargs):\n",
    "    \"\"\"\n",
    "    Calculate lcb from AP\n",
    "    \"\"\"\n",
    "    return simps(y=area*x,x=x)/np.trapz(y=area,x=x)\n",
    "\n",
    "def calculate_dispacement(x, area, **kwargs):\n",
    "    \"\"\"\n",
    "    Calculate displacement\n",
    "    \"\"\"\n",
    "    return np.trapz(y=area,x=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DraughtError(ValueError): pass\n",
    "\n",
    "def define_indata(row, sections, rho=1000,  g=9.81):\n",
    "    \n",
    "    indata = Indata()\n",
    "    \n",
    "    draught=(row.TA+row.TF)/2\n",
    "    indata.draught=draught\n",
    "    if draught<=sections['t'].max():\n",
    "        sections = cut_sections(sections, draught)\n",
    "    else:\n",
    "        raise DraughtError('Draught is too large for sections')\n",
    "    \n",
    "    sections=add_cScores(sections)\n",
    "    \n",
    "    indata.cScores=np.array(sections['cScores'])\n",
    "    indata.ts=np.array(sections['t'])\n",
    "    indata.bs=np.array(sections['b'])\n",
    "    indata.zbars=np.zeros_like(sections['b'])  # Guessing...\n",
    "        \n",
    "    beam=sections['b'].max()\n",
    "    indata.lpp=sections['x'].max()-sections['x'].min()\n",
    "    #indata.displacement=row.Volume\n",
    "    indata.displacement=calculate_dispacement(**sections)\n",
    "    \n",
    "    indata.g=g\n",
    "    indata.kxx=row.KXX\n",
    "    indata.kyy=row.lpp*0.4\n",
    "    lcb=calculate_lcb(x=sections['x'], area=sections['area'])\n",
    "    indata.lcb=lcb-row.lpp/2\n",
    "    indata.lpp=row.lpp\n",
    "    indata.projectName='loading_condition_id_%i' % row.loading_condition_id\n",
    "    \n",
    "    indata.rho=rho\n",
    "    indata.zcg=row.kg-draught\n",
    "    #indata.waveFrequenciesMin=0.2\n",
    "    #indata.waveFrequenciesMax=0.5\n",
    "    #indata.waveFrequenciesIncrement=0.006\n",
    "    w=row.omega0/np.sqrt(row.scale_factor)\n",
    "    indata.waveFrequenciesMin=w*0.5\n",
    "    indata.waveFrequenciesMax=w*2.0\n",
    "    N=40\n",
    "    indata.waveFrequenciesIncrement=(indata.waveFrequenciesMax-indata.waveFrequenciesMin)/N\n",
    "    indata.runOptions[\"IE\"].set_value(1)\n",
    "    \n",
    "    return indata,sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ikeda(row, indata, output_file, fi_a):\n",
    "\n",
    "    w = row.omega0\n",
    "    scale_factor=row.scale_factor\n",
    "    V = row.ship_speed*1.852/3.6/np.sqrt(scale_factor)\n",
    "    R = 0.01*row.beam/scale_factor\n",
    "    lBK=row.BKL/scale_factor\n",
    "    bBK=row.BKB/scale_factor\n",
    "    ikeda = Ikeda.load_scoresII(V=V, w=w, fi_a=fi_a, indata=indata, output_file=output_file, \n",
    "                                scale_factor=scale_factor, lBK=lBK, bBK=bBK)\n",
    "    \n",
    "    ikeda.R = R\n",
    "    return ikeda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ikeda(ikeda):\n",
    "\n",
    "    output = {}\n",
    "    output['B_44_hat'] = ikeda.calculate_B44()[0]\n",
    "    output['B_W0_hat'] =ikeda.calculate_B_W0()[0]\n",
    "    output['B_W_hat'] =ikeda.calculate_B_W()[0]\n",
    "    output['B_F_hat'] =ikeda.calculate_B_F()[0]\n",
    "    output['B_E_hat'] =ikeda.calculate_B_E()[0]\n",
    "    output['B_BK_hat'] =ikeda.calculate_B_BK()[0]\n",
    "    output['B_L_hat'] =ikeda.calculate_B_L()[0]\n",
    "    output['Bw_div_Bw0'] =ikeda.calculate_Bw_div_Bw0()[0]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "fi_a = np.deg2rad(10)\n",
    "for run_name, row in df.iterrows():\n",
    "    loading_condition_id=row['loading_condition_id']\n",
    "    sections = section_groups.get_group(loading_condition_id)\n",
    "    sections=remove_duplicate_sections(sections)\n",
    "    sections=too_small_sections(sections)\n",
    "    \n",
    "    try:\n",
    "        indata,sections_ = define_indata(row, sections)\n",
    "    except DraughtError as e:\n",
    "        print('Draught is too large for sections, this loading condition is skipped.')\n",
    "        continue\n",
    "\n",
    "        \n",
    "    save_name='%s.in' % row.loading_condition_id\n",
    "    save_path=os.path.join('scores2',save_name)\n",
    "    indata.save(save_path)\n",
    "    \n",
    "    calculation = Calculation(outDataDirectory='scores2/result')\n",
    "    \n",
    "    # Run scoresII:\n",
    "    try:\n",
    "        calculation.run(indata=indata, b_div_t_max=None, timeout=1.0)\n",
    "    except TDPError:\n",
    "        print('Dissregarding the TDPError')\n",
    "        continue\n",
    "    except pyscores2.LcgError as e:\n",
    "        print('Disregarded')\n",
    "        print(e)\n",
    "        continue\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print('Disregarded, scoresII got stuck...')\n",
    "        continue\n",
    "        \n",
    "    output_file = OutputFile(filePath=calculation.outDataPath)\n",
    "    ikeda = create_ikeda(row=row, indata=indata, output_file=output_file, fi_a=fi_a)\n",
    "    result_data = calculate_ikeda(ikeda)\n",
    "    result=pd.Series(data=result_data, name=row.name)\n",
    "    results=results.append(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Also run Simplified Ikeda for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_si(si):\n",
    "\n",
    "    output = pd.DataFrame()\n",
    "    output['B_44_hat'] = si.calculate_B44()\n",
    "    output['B_W0_hat'] =si.calculate_B_W0()\n",
    "    output['B_W_hat'] =si.calculate_B_W()\n",
    "    output['B_F_hat'] =si.calculate_B_F()\n",
    "    output['B_E_hat'] =si.calculate_B_E()\n",
    "    output['B_BK_hat'] =si.calculate_B_BK()\n",
    "    output['B_L_hat'] =si.calculate_B_L()\n",
    "    output['Bw_div_Bw0'] =si.calculate_Bw_div_Bw0()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_si=pd.DataFrame()\n",
    "inputs_si['w']=df['omega0']  # Already model scale\n",
    "scale_factor=df['scale_factor']\n",
    "inputs_si['V']=df['ship_speed']*1.852/3.6/np.sqrt(scale_factor)\n",
    "inputs_si['fi_a']=fi_a\n",
    "inputs_si['beam']=df['beam']/scale_factor\n",
    "inputs_si['lpp']=df['lpp']/scale_factor\n",
    "inputs_si['kg']=df['kg']/scale_factor\n",
    "inputs_si['volume']=df['Volume']/(scale_factor**3)\n",
    "draught=(df['TA']+df['TF'])/2\n",
    "inputs_si['draught']=draught/scale_factor\n",
    "inputs_si['A0']=df['A0']\n",
    "inputs_si['lBK']=df['BKL']/scale_factor\n",
    "inputs_si['bBK']=df['BKB']/scale_factor\n",
    "si = SimplifiedIkeda(**inputs_si)\n",
    "results_si = calculate_si(si)\n",
    "results_si.index=df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make comparison with model tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_e = lambdas.B_e_lambda(B_1=df['B_1'], B_2=df['B_2'], phi_a=fi_a, \n",
    "                   omega0=df['omega0'])\n",
    "\n",
    "scale_factor = df['scale_factor']\n",
    "Volume = df['Volume']/(scale_factor**3)\n",
    "beam = df['beam']/scale_factor\n",
    "g=9.81\n",
    "rho=1000\n",
    "\n",
    "df['B_e_hat'] = lambdas.B_e_hat_lambda(B_e=B_e, Disp=Volume, beam=beam, \n",
    "                                 g=g, rho=rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.merge(left=results, right=results_si, how='inner', left_index=True, right_index=True,\n",
    "                     suffixes=('_ikeda','_si'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_results['B_44_hat_ikeda'].notnull()\n",
    "df_results = df_results.loc[mask].copy()\n",
    "\n",
    "\n",
    "df_compare = pd.merge(left=df, right=df_results, how='inner', left_index=True, right_index=True,\n",
    "                     suffixes=('','_y'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "df_compare.plot(x='B_44_hat_ikeda', y='B_44_hat_si', ax=ax, style='o')\n",
    "\n",
    "ax.set_xlabel(r'$\\hat{B_{44}}$ (Ikeda)')\n",
    "ax.set_ylabel(r'$\\hat{B_{44}}$ (SI)')\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "lim = np.max([xlim[1],ylim[1]])\n",
    "ax.set_xlim(0,lim)\n",
    "ax.set_ylim(0,lim)\n",
    "ax.plot([0,lim],[0,lim],'r-')\n",
    "\n",
    "ax.grid(True)\n",
    "ax.set_aspect('equal', 'box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "df_compare.plot(x='B_e_hat', y='B_44_hat_ikeda', ax=ax, style='.', \n",
    "                label=r'$\\hat{B_{44}}$ Ikeda')\n",
    "\n",
    "df_compare.plot(x='B_e_hat', y='B_44_hat_si', ax=ax, style='.', \n",
    "                label=r'$\\hat{B_{44}}$ SI')\n",
    "\n",
    "ax.set_xlabel(r'$\\hat{B_{44}}$ (model test)')\n",
    "ax.set_ylabel(r'$\\hat{B_{44}}$ (prediction)')\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "lim = np.max([xlim[1],ylim[1]])\n",
    "ax.set_xlim(0,lim)\n",
    "ax.set_ylim(0,lim)\n",
    "ax.set_title('Total roll damping for Ikeda, Simplified Ikeda and model tests')\n",
    "ax.plot([0,lim],[0,lim],'r-')\n",
    "\n",
    "ax.grid(True)\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_true=df_compare['B_e_hat'], y_pred=df_compare['B_44_hat_ikeda'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_true=df_compare['B_e_hat'], y_pred=df_compare['B_44_hat_si'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating the residuals\n",
    "<a id=\"residuals\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_residuals(suffix_true='_ikeda', suffix_prediction='_si'):\n",
    "    prefixes = ['B_44_hat',\n",
    "                'B_W0_hat',\n",
    "                'B_W_hat',\n",
    "                'B_F_hat',\n",
    "                'B_E_hat',\n",
    "                'B_BK_hat',\n",
    "                'B_L_hat', \n",
    "                'Bw_div_Bw0',]\n",
    "    \n",
    "    for prefix in prefixes:\n",
    "        residual_name = '%s_residual%s%s' % (prefix, suffix_prediction, suffix_true)\n",
    "        name_true='%s%s' % (prefix, suffix_true)\n",
    "        name_prediction='%s%s' % (prefix, suffix_prediction)\n",
    "        \n",
    "        df_compare[residual_name] = df_compare[name_prediction] - df_compare[name_true]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_residuals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; \n",
    "#sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare['draught']=(df_compare['TA'] + df_compare['TF'])/2\n",
    "df_compare[r'LBK/Lpp']=df_compare['BKL']/df_compare['lpp']\n",
    "df_compare[r'BBK/beam']=df_compare['BKB']/df_compare['beam']\n",
    "df_compare['omega_hat']=lambdas.omega_hat(beam=df_compare['beam'], g=g, omega0=df_compare['omega0'])\n",
    "\n",
    "df_compare['Cb']=df_compare['Volume']/(df_compare['lpp']*df_compare['beam']*df_compare['draught'])\n",
    "interesting=['Cb','A0','OG/d','LBK/Lpp','BBK/beam','omega_hat',r'beam/draught', 'Fn']\n",
    "sns.pairplot(df_compare,y_vars='B_44_hat_residual_si_ikeda', x_vars=interesting, aspect=0.6);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting2=[\n",
    "#'B_44_hat_residual_si_ikeda',\n",
    "'B_W0_hat_residual_si_ikeda',\n",
    "'B_W_hat_residual_si_ikeda',\n",
    "'B_F_hat_residual_si_ikeda',\n",
    "'B_E_hat_residual_si_ikeda',\n",
    "'B_BK_hat_residual_si_ikeda',\n",
    "'B_L_hat_residual_si_ikeda', \n",
    "]\n",
    "\n",
    "sns.pairplot(df_compare,y_vars='residual_si', x_vars=interesting2, aspect=0.6);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix_true='_ikeda'\n",
    "suffix_prediction='_si'\n",
    "prefixes = [\n",
    "    'B_W0_hat',\n",
    "    'B_W_hat',\n",
    "    'B_F_hat',\n",
    "    'B_E_hat',\n",
    "    'B_BK_hat',\n",
    "    'B_L_hat',]\n",
    "\n",
    "lim = np.max([df_compare['B_44_hat_ikeda'].max(),\n",
    "              df_compare['B_44_hat_si'].max(),\n",
    "             ])\n",
    "    \n",
    "\n",
    "for prefix in prefixes:\n",
    "    \n",
    "    name_true='%s%s' % (prefix, suffix_true)\n",
    "    name_prediction='%s%s' % (prefix, suffix_prediction)\n",
    "        \n",
    "    fig,ax=plt.subplots()\n",
    "    df_compare.plot(x=name_true, y=name_prediction, ax=ax, style='.')\n",
    "    \n",
    "    \n",
    "    #ax.set_xlabel(r'$\\hat{B_{44}}$ (model test)')\n",
    "    #ax.set_ylabel(r'$\\hat{B_{44}}$ (prediction)')\n",
    "        \n",
    "    ax.set_xlim(0,lim)\n",
    "    ax.set_ylim(0,lim)\n",
    "    #ax.set_title('Total roll damping for Ikeda, Simplified Ikeda and model tests')\n",
    "    ax.plot([0,lim],[0,lim],'r-')\n",
    "    \n",
    "    ax.grid(True)\n",
    "    ax.set_aspect('equal', 'box')\n",
    "    ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
