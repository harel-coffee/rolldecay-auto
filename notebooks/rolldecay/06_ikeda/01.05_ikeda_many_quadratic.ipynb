{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ikeda for many ships with quadratic contributions\n",
    "The method developed in: ([01.03_ikeda_many_dev](06_ikeda/01.03_ikeda_many_dev.ipynb)) will now be attempted for many ships.\n",
    "Instead of just calculating ikeda for one roll amplitude, it will now be calculated for 2 amplitudes to derive the quadratic part $B_2$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../../imports.py\n",
    "\"\"\"\n",
    "These is the standard setup for the notebooks.\n",
    "\"\"\"\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#from jupyterthemes import jtplot\n",
    "#jtplot.style(theme='onedork', context='notebook', ticks=True, grid=False)\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.style.use('paper')\n",
    "\n",
    "#import data\n",
    "import copy\n",
    "from rolldecay.bis_system import BisSystem\n",
    "from rolldecay import database\n",
    "from mdldb.tables import Run\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from rolldecayestimators.transformers import CutTransformer, LowpassFilterDerivatorTransformer, ScaleFactorTransformer, OffsetTransformer\n",
    "from rolldecayestimators.direct_estimator_cubic import EstimatorQuadraticB, EstimatorCubic\n",
    "from rolldecayestimators.ikeda_estimator import IkedaQuadraticEstimator\n",
    "import rolldecayestimators.equations as equations\n",
    "import rolldecayestimators.lambdas as lambdas\n",
    "from rolldecayestimators.substitute_dynamic_symbols import lambdify\n",
    "import rolldecayestimators.symbols as symbols\n",
    "import sympy as sp\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "import rolldecay.paper_writing as paper_writing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyscores2.indata import Indata\n",
    "from pyscores2.runScores2 import Calculation\n",
    "from pyscores2.output import OutputFile\n",
    "from pyscores2 import TDPError\n",
    "import pyscores2\n",
    "from rolldecayestimators.ikeda import Ikeda, IkedaR\n",
    "from rolldecayestimators.simplified_ikeda_class import SimplifiedIkeda\n",
    "import subprocess\n",
    "from rolldecayestimators import measure\n",
    "import rolldecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_sections_id = pd.read_csv('all_sections.csv', sep=';')\n",
    "df_all_sections_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_groups=df_all_sections_id.groupby(by='loading_condition_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loading_condition_ids = df_all_sections_id['loading_condition_id'].unique()\n",
    "mask=pd.notnull(loading_condition_ids)\n",
    "loading_condition_ids=loading_condition_ids[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rolldecay = database.load(rolldecay_table_name='rolldecay_quadratic_b', limit_score=0.99, \n",
    "                             exclude_table_name='rolldecay_exclude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=df_rolldecay['loading_condition_id'].isin(loading_condition_ids)\n",
    "df=df_rolldecay.loc[mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BKB'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cScores(sections):\n",
    "    sections=sections.copy()\n",
    "    sections['cScores']=sections['area']/(sections['b']*sections['t'])\n",
    "    mask=sections['cScores']>1\n",
    "    sections.loc[mask,'cScores']=1\n",
    "    return sections\n",
    "\n",
    "def cut_sections(sections, draught):\n",
    "    sections=sections.copy()\n",
    "    mask = sections['t']>draught\n",
    "    sections.loc[mask,'t']=draught\n",
    "    sections.loc[mask,'area']-=draught*sections['b'].max()  # Assuming rectangular shape\n",
    "    return sections\n",
    "\n",
    "def remove_duplicate_sections(sections):\n",
    "    sections=sections.copy()\n",
    "    mask=~sections['x'].duplicated()\n",
    "    sections=sections.loc[mask]\n",
    "    assert sections['x'].is_unique\n",
    "    return sections\n",
    "\n",
    "def too_small_sections(sections):\n",
    "    sections=sections.copy()\n",
    "    small = 0.1\n",
    "    mask=sections['b']==0\n",
    "    sections.loc[mask,'b']=small\n",
    "    mask=sections['t']==0\n",
    "    sections.loc[mask,'t']=small\n",
    "    mask=sections['area']==0\n",
    "    sections.loc[mask,'area']=small\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import simps\n",
    "def calculate_lcb(x, area, **kwargs):\n",
    "    \"\"\"\n",
    "    Calculate lcb from AP\n",
    "    \"\"\"\n",
    "    return simps(y=area*x,x=x)/np.trapz(y=area,x=x)\n",
    "\n",
    "def calculate_dispacement(x, area, **kwargs):\n",
    "    \"\"\"\n",
    "    Calculate displacement\n",
    "    \"\"\"\n",
    "    return np.trapz(y=area,x=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DraughtError(ValueError): pass\n",
    "\n",
    "def define_indata(row, sections, rho=1000,  g=9.81):\n",
    "    \n",
    "    indata = Indata()\n",
    "    \n",
    "    draught=(row.TA+row.TF)/2\n",
    "    indata.draught=draught\n",
    "    if draught<=sections['t'].max():\n",
    "        sections = cut_sections(sections, draught)\n",
    "    else:\n",
    "        raise DraughtError('Draught is too large for sections')\n",
    "    \n",
    "    sections=add_cScores(sections)\n",
    "    \n",
    "    indata.cScores=np.array(sections['cScores'])\n",
    "    indata.ts=np.array(sections['t'])\n",
    "    indata.bs=np.array(sections['b'])\n",
    "    indata.zbars=np.zeros_like(sections['b'])  # Guessing...\n",
    "        \n",
    "    beam=sections['b'].max()\n",
    "    indata.lpp=sections['x'].max()-sections['x'].min()\n",
    "    #indata.displacement=row.Volume\n",
    "    indata.displacement=calculate_dispacement(**sections)\n",
    "    \n",
    "    indata.g=g\n",
    "    indata.kxx=row.KXX\n",
    "    indata.kyy=row.lpp*0.4\n",
    "    lcb=calculate_lcb(x=sections['x'], area=sections['area'])\n",
    "    indata.lcb=lcb-row.lpp/2\n",
    "    indata.lpp=row.lpp\n",
    "    indata.projectName='loading_condition_id_%i' % row.loading_condition_id\n",
    "    \n",
    "    indata.rho=rho\n",
    "    indata.zcg=row.kg-draught\n",
    "    #indata.waveFrequenciesMin=0.2\n",
    "    #indata.waveFrequenciesMax=0.5\n",
    "    #indata.waveFrequenciesIncrement=0.006\n",
    "    w=row.omega0/np.sqrt(row.scale_factor)\n",
    "    indata.waveFrequenciesMin=w*0.5\n",
    "    indata.waveFrequenciesMax=w*2.0\n",
    "    N=40\n",
    "    indata.waveFrequenciesIncrement=(indata.waveFrequenciesMax-indata.waveFrequenciesMin)/N\n",
    "    indata.runOptions[\"IE\"].set_value(1)\n",
    "    \n",
    "    return indata,sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ikeda(row, indata, output_file, fi_a):\n",
    "\n",
    "    w = row.omega0\n",
    "    scale_factor=row.scale_factor\n",
    "    V = row.ship_speed*1.852/3.6/np.sqrt(scale_factor)\n",
    "    R = 0.01*row.beam/scale_factor\n",
    "    lBK=row.BKL/scale_factor\n",
    "    bBK=row.BKB/scale_factor\n",
    "    ikeda = Ikeda.load_scoresII(V=V, w=w, fi_a=fi_a, indata=indata, output_file=output_file, \n",
    "                                scale_factor=scale_factor, lBK=lBK, bBK=bBK)\n",
    "    \n",
    "    ikeda.R = R\n",
    "    return ikeda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ikeda(ikeda):\n",
    "\n",
    "    output = pd.DataFrame()\n",
    "    output['B_44_hat']   = ikeda.calculate_B44()\n",
    "    output['B_W0_hat']   = float(ikeda.calculate_B_W0())\n",
    "    output['B_W_hat']    = float(ikeda.calculate_B_W())\n",
    "    output['B_F_hat']    = ikeda.calculate_B_F()\n",
    "    output['B_E_hat']    = ikeda.calculate_B_E()\n",
    "    output['B_BK_hat']   = ikeda.calculate_B_BK()\n",
    "    output['B_L_hat']    = float(ikeda.calculate_B_L())\n",
    "    output['Bw_div_Bw0'] = float(ikeda.calculate_Bw_div_Bw0())\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_B_1_B2(s1,s2,fi_as:np.ndarray):    \n",
    "    \n",
    "    # Derive linear and quadratic part for all components:\n",
    "    \n",
    "    if isinstance(s1,pd.Series):\n",
    "        result=pd.Series(name=row.name)\n",
    "        columns = s1.index\n",
    "    elif isinstance(s1,pd.DataFrame):\n",
    "        result=pd.DataFrame()\n",
    "        columns = s1.columns\n",
    "    else:\n",
    "        raise ValueError('s1 must be pd.Series or pd.DataFrame')\n",
    "    \n",
    "    x = fi_as*8*row.omega0/(3 * np.pi)\n",
    "    B_2 = (s2 - s1) / (x[1] - x[0])\n",
    "    B_1 = s1 - B_2 * x[0]\n",
    "    \n",
    "    # Save all of the component as one linear term: _1 and a quadratic term: _2\n",
    "    \n",
    "    \n",
    "    for key in columns:\n",
    "        new_name_1 = '%s_1' % key\n",
    "        result[new_name_1] = s1[key]\n",
    "\n",
    "        new_name_2 = '%s_2' % key\n",
    "        result[new_name_2] = s2[key]\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "fi_as = np.deg2rad([1,10])\n",
    "for run_name, row in df.iterrows():\n",
    "    loading_condition_id=row['loading_condition_id']\n",
    "    sections = section_groups.get_group(loading_condition_id)\n",
    "    sections=remove_duplicate_sections(sections)\n",
    "    sections=too_small_sections(sections)\n",
    "    \n",
    "    try:\n",
    "        indata,sections_ = define_indata(row, sections)\n",
    "    except DraughtError as e:\n",
    "        print('Draught is too large for sections, this loading condition is skipped.')\n",
    "        continue\n",
    "\n",
    "        \n",
    "    save_name='%s.in' % row.loading_condition_id\n",
    "    save_path=os.path.join('scores2',save_name)\n",
    "    indata.save(save_path)\n",
    "    \n",
    "    calculation = Calculation(outDataDirectory='scores2/result')\n",
    "    \n",
    "    # Run scoresII:\n",
    "    try:\n",
    "        calculation.run(indata=indata, b_div_t_max=None, timeout=1.0)\n",
    "    except TDPError:\n",
    "        print('Dissregarding the TDPError')\n",
    "        continue\n",
    "    except pyscores2.LcgError as e:\n",
    "        print('Disregarded')\n",
    "        print(e)\n",
    "        continue\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print('Disregarded, scoresII got stuck...')\n",
    "        continue\n",
    "        \n",
    "    output_file = OutputFile(filePath=calculation.outDataPath)\n",
    "    \n",
    "    \n",
    "    ikeda = create_ikeda(row=row, indata=indata, output_file=output_file, fi_a=fi_as)\n",
    "    result_datas = calculate_ikeda(ikeda)  # DataFrame with two roll amplitudes\n",
    "    \n",
    "    # Derive linear and quadratic part for all components:\n",
    "    s1=result_datas.iloc[0]\n",
    "    s2=result_datas.iloc[1]\n",
    "    result = get_B_1_B2(s1=s1, s2=s2, fi_as=fi_as)\n",
    "    \n",
    "    \n",
    "    results=results.append(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['id']=results.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make comparison with model tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "scale_factor = df2['scale_factor']\n",
    "df2['Volume']/=(scale_factor**3)\n",
    "df2['Disp']=df2['Volume']\n",
    "df2['beam']/=scale_factor\n",
    "df2['lpp']/=scale_factor\n",
    "df2['kg']/=scale_factor\n",
    "df2['BKB']/=scale_factor\n",
    "df2['BKL']/=scale_factor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Disp']=df2['Volume']\n",
    "results['Disp']=df2.loc[results.index,'Disp']\n",
    "results['omega0']=df2.loc[results.index,'omega0']\n",
    "\n",
    "#df_compare = measure.linearized_matrix(df_rolldecay=df2, df_ikeda=results, do_hatify=False)\n",
    "#mask=df_compare['B_e_hat_ikeda'].notnull()\n",
    "#df_compare=df_compare.loc[mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearize_model_tests(df_rolldecay, phi_as = np.deg2rad(np.linspace(1,10,10)), g=9.81, rho=1000):\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for phi_a in phi_as:\n",
    "        df_ = measure.linearize_model_test(phi_a=phi_a, df_rolldecay=df_rolldecay, g=g, rho=rho)\n",
    "        df_['phi_a']=phi_a\n",
    "        df =df.append(df_, ignore_index=True)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def linearize_ikedas(df_ikeda, phi_as = np.deg2rad(np.linspace(1,10,10)), g=9.81, rho=1000,\n",
    "                     components = ['B_44_hat', 'B_F_hat', 'B_W_hat', 'B_E_hat', 'B_BK_hat', 'B_L_hat']):\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    for phi_a in phi_as:\n",
    "        df_ = measure.linearize_si(phi_a=phi_a, df_ikeda=df_ikeda, do_hatify=False, components=components)\n",
    "        df_['phi_a']=phi_a\n",
    "        df =df.append(df_, ignore_index=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rolldecays=linearize_model_tests(df_rolldecay=df2)\n",
    "df_ikedas=linearize_ikedas(df_ikeda=results)\n",
    "df_ikedas.dropna(subset=['B_e_hat'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare = pd.merge(left=df_rolldecays, right=df_ikedas, how='inner', left_on=('id','phi_a'), right_on=('id','phi_a'), suffixes=('','_ikeda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "df_compare.plot(x='B_e_hat', y='B_e_hat_ikeda', ax=ax, style='o', alpha=0.05, ms=20, markeredgewidth=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_true=df_compare['B_e_hat'], y_pred=df_compare['B_e_hat_ikeda'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Also run Simplified Ikeda for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_si(si):\n",
    "\n",
    "    output = pd.DataFrame()\n",
    "    output['B_44_hat'] = si.calculate_B44()\n",
    "    output['B_W0_hat'] =si.calculate_B_W0()\n",
    "    output['B_W_hat'] =si.calculate_B_W()\n",
    "    output['B_F_hat'] =si.calculate_B_F()\n",
    "    output['B_E_hat'] =si.calculate_B_E()\n",
    "    output['B_BK_hat'] =si.calculate_B_BK()\n",
    "    output['B_L_hat'] =si.calculate_B_L()\n",
    "    output['Bw_div_Bw0'] =si.calculate_Bw_div_Bw0()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_si=pd.DataFrame()\n",
    "inputs_si['w']=df['omega0']  # Already model scale\n",
    "scale_factor=df['scale_factor']\n",
    "inputs_si['V']=df['ship_speed']*1.852/3.6/np.sqrt(scale_factor)\n",
    "inputs_si['beam']=df['beam']/scale_factor\n",
    "inputs_si['lpp']=df['lpp']/scale_factor\n",
    "inputs_si['kg']=df['kg']/scale_factor\n",
    "inputs_si['volume']=df['Volume']/(scale_factor**3)\n",
    "draught=(df['TA']+df['TF'])/2\n",
    "inputs_si['draught']=draught/scale_factor\n",
    "inputs_si['A0']=df['A0']\n",
    "inputs_si['lBK']=df['BKL']/scale_factor\n",
    "inputs_si['bBK']=df['BKB']/scale_factor\n",
    "\n",
    "inputs_si_1=inputs_si.copy()\n",
    "inputs_si_2=inputs_si.copy()\n",
    "\n",
    "\n",
    "inputs_si_1['fi_a']=fi_as[0]\n",
    "si_1 = SimplifiedIkeda(**inputs_si_1)\n",
    "results_si_1 = calculate_si(si_1)\n",
    "\n",
    "inputs_si_2['fi_a']=fi_as[1]\n",
    "si_2 = SimplifiedIkeda(**inputs_si_2)\n",
    "results_si_2 = calculate_si(si_2)\n",
    "\n",
    "results_si=get_B_1_B2(s1=results_si_1, s2=results_si_2, fi_as=fi_as)\n",
    "results_si.index=df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_si['Disp']=df2.loc[results_si.index,'Disp']\n",
    "results_si['omega0']=df2.loc[results_si.index,'omega0']\n",
    "results_si['id']=results_si.index\n",
    "#df_compare_si = measure.linearized_matrix(df_rolldecay=df2, df_ikeda=results_si, do_hatify=False, suffixes=('','_si'))\n",
    "df_sis=linearize_ikedas(df_ikeda=results_si)\n",
    "df_sis.dropna(subset=['B_e_hat'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare_ikeda_si = pd.merge(left=df_ikedas, right=df_sis, how='inner', left_on=('id','phi_a'), right_on=('id','phi_a'), suffixes=('_ikeda','_si'))\n",
    "df_compare_all = pd.merge(left=df_rolldecays, right=df_compare_ikeda_si, how='inner', left_on=('id','phi_a'), right_on=('id','phi_a'), suffixes=('','_ikedas'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "df_compare_all.plot(x='B_e_hat', y=['B_e_hat_ikeda','B_e_hat_si'], ax=ax, style='o', alpha=0.40, ms=5, markeredgewidth=0)\n",
    "\n",
    "ax.set_xlabel(r'$\\hat{B_{44}}$ (Ikeda)')\n",
    "ax.set_ylabel(r'$\\hat{B_{44}}$ (SI)')\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "lim = np.max([xlim[1],ylim[1]])\n",
    "ax.set_xlim(0,lim)\n",
    "ax.set_ylim(0,lim)\n",
    "ax.plot([0,lim],[0,lim],'r-')\n",
    "\n",
    "ax.grid(True)\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax.get_legend().remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model_si_ikeda\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=3.5\n",
    "with plt.style.context('paper'):\n",
    "    fig,ax=plt.subplots()\n",
    "    fig.set_size_inches(size,size)\n",
    "    \n",
    "    df_compare_all.plot(x='B_e_hat', y='B_e_hat_si', ax=ax, style='+', \n",
    "                    label=r'$\\hat{B}_e^{SI}$')\n",
    "\n",
    "    df_compare_all.plot(x='B_e_hat', y='B_e_hat_ikeda', ax=ax, style='.', \n",
    "                    label=r'$\\hat{B}_e^{Ikeda}$')\n",
    "    \n",
    "    ax.set_xlabel(r'$\\hat{B}_e^{Model}$')\n",
    "    ax.set_ylabel(r'$\\hat{B}_e$')\n",
    "    \n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    lim = np.max([xlim[1],ylim[1]])\n",
    "    ax.set_xlim(0,lim)\n",
    "    ax.set_ylim(0,lim)\n",
    "    #ax.set_title('Total roll damping for Ikeda, Simplified Ikeda and model tests')\n",
    "    ax.plot([0,lim],[0,lim],'r-')\n",
    "    \n",
    "    ax.grid(True)\n",
    "    ax.set_aspect('equal', 'box')\n",
    "    ax.legend();\n",
    "    paper_writing.save_fig(fig=fig, name='si_ikeda_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare_all['B_44_fraction_si_ikeda'] = df_compare_all['B_e_hat_si']/df_compare_all['B_e_hat_ikeda']\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "df_compare_all.plot(x='B_e_hat', y='B_44_fraction_si_ikeda', ax=ax, style='.')\n",
    "ax.set_xlabel(r'$\\hat{B_{44}}$')\n",
    "ax.set_ylabel(r'$\\frac{B_{44}(SI)}{B_{44}(Ikeda)}$')\n",
    "\n",
    "ax.get_legend().remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_true=df_compare_all['B_e_hat'], y_pred=df_compare_all['B_e_hat_ikeda'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_true=df_compare_all['B_e_hat'], y_pred=df_compare_all['B_e_hat_si'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating the residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_residuals(suffix_true='_ikeda', suffix_prediction='_si'):\n",
    "    prefixes = ['B_e_hat',\n",
    "                #'B_W0_hat_e',\n",
    "                'B_W_hat_e',\n",
    "                'B_F_hat_e',\n",
    "                'B_E_hat_e',\n",
    "                'B_BK_hat_e',\n",
    "                'B_L_hat_e', \n",
    "                #'Bw_div_Bw0',\n",
    "               ]\n",
    "    \n",
    "    for prefix in prefixes:\n",
    "        residual_name = '%s_residual%s%s' % (prefix, suffix_prediction, suffix_true)\n",
    "        name_true='%s%s' % (prefix, suffix_true)\n",
    "        name_prediction='%s%s' % (prefix, suffix_prediction)\n",
    "        \n",
    "        df_compare_all[residual_name] = df_compare_all[name_prediction] - df_compare_all[name_true]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_residuals()\n",
    "df_compare_all['B_e_hat_residual_si_model'] = df_compare_all['B_e_hat_si'] - df_compare_all['B_e_hat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; \n",
    "#sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"residuals\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=9.81\n",
    "df_compare_all['draught']=((df_compare_all['TA'] + df_compare_all['TF'])/2)/df_compare_all['scale_factor']\n",
    "df_compare_all['OG']=df_compare_all['draught']-df_compare_all['kg']\n",
    "df_compare_all['beam/draught']=df_compare_all['beam']/df_compare_all['draught']\n",
    "df_compare_all['V']=df_compare_all['ship_speed']*1.852\n",
    "df_compare_all['Fn']=df_compare_all['V']/(np.sqrt(df_compare_all['lpp']*g))\n",
    "df_compare_all[r'OG/d']=df_compare_all['OG']/df_compare_all['draught']\n",
    "df_compare_all[r'LBK/Lpp']=df_compare_all['BKL']/df_compare_all['lpp']\n",
    "df_compare_all[r'BBK/beam']=df_compare_all['BKB']/df_compare_all['beam']\n",
    "df_compare_all['omega_hat']=lambdas.omega_hat(beam=df_compare_all['beam'], g=g, omega0=df_compare_all['omega0'])\n",
    "\n",
    "df_compare_all['Cb']=df_compare_all['Volume']/(df_compare_all['lpp']*df_compare_all['beam']*df_compare_all['draught'])\n",
    "interesting=['Cb','A0','OG/d','LBK/Lpp','BBK/beam','omega_hat',r'beam/draught', 'Fn']\n",
    "#sns.lmplot(data=df_compare,y='B_44_hat_residual_si_ikeda', x=interesting, aspect=0.6);\n",
    "sns.pairplot(df_compare_all,y_vars='B_e_hat_residual_si_ikeda', x_vars=interesting, aspect=0.6);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_compare_all[interesting+['B_e_hat_residual_si_ikeda']].corr().abs()\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "corr.plot(y='B_e_hat_residual_si_ikeda', kind='bar', ax=ax);\n",
    "ax.set_title('Absolut correlation coefficient for the error');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('paper'):\n",
    "    \n",
    "    y='B_e_hat_residual_si_model'\n",
    "    \n",
    "    ylabel=r'$\\hat{B}_{e}^{SI}-\\hat{B}_{e}^{Model}$'\n",
    "    fig,ax=plt.subplots()\n",
    "    fig.set_size_inches(size,size)\n",
    "    \n",
    "    df_compare_all.plot(x=r'beam/draught',y=y, ax=ax, style='.')\n",
    "    \n",
    "    \n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xlabel(r'$\\frac{beam}{T}$ [-]')\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.grid(True)\n",
    "    ax.get_legend().remove()\n",
    "    paper_writing.save_fig(fig, name='beam_T_residual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as  sns\n",
    "\n",
    "g = sns.jointplot(x=r'beam/draught', y='B_e_hat_residual_si_model', data=df_compare_all,\n",
    "                  kind=\"reg\", truncate=False,\n",
    "                  color=\"m\", height=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels={\n",
    "'Cb' : r'$C_b$ [-]',\n",
    "r'beam/draught' : r'$\\frac{beam}{T}$ [-]',\n",
    "r'OG/d' : r'$\\frac{\\overline{OG}}{T}$ [-]',\n",
    "'A0' : r'$A_{0}$ [-]',\n",
    "r'BBK/beam' : r'$\\frac{BK_B}{beam}$ [-]',\n",
    "r'LBK/Lpp' : r'$\\frac{BK_L}{L_{pp}}$ [-]',\n",
    "r'omega_hat' : r'$\\hat{\\omega}$ [-]',\n",
    "r'fi_a' : r'$\\phi_a$ [rad]',\n",
    "r'Fn' : r'$F_n$ [-]',\n",
    "    \n",
    "}\n",
    "\n",
    "with plt.style.context('paper'):\n",
    "    fig,ax=plt.subplots()\n",
    "    fig.set_size_inches(size,size)\n",
    "    \n",
    "    df_compare_all['B_e_hat_residual_si_model_abs'] = df_compare_all['B_e_hat_residual_si_model'].abs()\n",
    "    \n",
    "    for y in interesting:\n",
    "        \n",
    "        df_=df_compare_all.sort_values(by=y)\n",
    "        y_=df_[y].abs()\n",
    "        y_-=y_.min()\n",
    "        \n",
    "        ax.plot(df_['B_e_hat_residual_si_model_abs'], y_, '.', label=labels[y])\n",
    "    \n",
    "    \n",
    "    ax.set_xlabel(r'$|\\hat{B}_{e}^{SI}-\\hat{B}_{e}^{Model}|$')\n",
    "    ax.set_ylabel('change')\n",
    "\n",
    "    ax.grid(True)\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(1.30, 0.8),\n",
    "          ncol=1)\n",
    "    \n",
    "    paper_writing.save_fig(fig, name='parameter_residual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing damping contributions SI vs. model test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix_true='_ikeda'\n",
    "suffix_prediction='_si'\n",
    "prefixes = [\n",
    "    'B_W_hat_e_si',\n",
    "    'B_F_hat_e_si',\n",
    "    'B_E_hat_e_si',\n",
    "    'B_BK_hat_e_si',\n",
    "    'B_L_hat_e_si',]\n",
    "\n",
    "labels=[\n",
    "    r'$\\hat{B_{W}}$',\n",
    "    r'$\\hat{B_{F}}$',\n",
    "    r'$\\hat{B_{E}}$',\n",
    "    r'$\\hat{B_{BK}}$',\n",
    "    r'$\\hat{B_{L}}$',\n",
    "    ]\n",
    "\n",
    "lim = np.max([df_compare_all['B_e_hat_ikeda'].max(),\n",
    "              df_compare_all['B_e_hat_si'].max(),\n",
    "             ])\n",
    "with plt.style.context('paper'):\n",
    "    \n",
    "    fig,ax=plt.subplots()\n",
    "    fig.set_size_inches(size,size)\n",
    "\n",
    "        \n",
    "        \n",
    "    df_compare_all.plot(x='B_e_hat_residual_si_model_abs', y=prefixes, style='.', label=labels, ax=ax)\n",
    "    ax.set_xlabel(r'$|\\hat{B}_{e}^{SI}-\\hat{B}_{e}^{Model}|$')\n",
    "        \n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    ax.set_ylabel(r'$\\hat{B}$ [-]')\n",
    "    \n",
    "    # (depricated) paper_writing.save_fig(fig, name='component_residual')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix_true='_ikeda'\n",
    "suffix_prediction='_si'\n",
    "prefixes = [\n",
    "    'B_W_hat_e',\n",
    "    'B_F_hat_e',\n",
    "    'B_E_hat_e',\n",
    "    'B_BK_hat_e',\n",
    "    'B_L_hat_e',]\n",
    "\n",
    "x_labels=['%s_ikeda' % label for label in prefixes]\n",
    "y_labels=['%s_si' % label for label in prefixes]\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "for prefix in prefixes:\n",
    "    x='%s_ikeda' % prefix\n",
    "    y='%s_si' % prefix\n",
    "    \n",
    "    df_compare_all.plot(x=x, y=y, label=prefix, ax=ax, style='.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"B_W_speed_factor_residual\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts=[\n",
    "'B_W_hat_e_si',\n",
    "'B_F_hat_e_si',\n",
    "'B_E_hat_e_si',\n",
    "'B_BK_hat_e_si',\n",
    "'B_L_hat_e_si',\n",
    "]\n",
    "\n",
    "df_compare_all['B_e_hat_residual_si_model_abs'] = df_compare_all['B_e_hat_residual_si_model'].abs()\n",
    "corr = df_compare_all[parts+['B_e_hat_residual_si_model_abs']].corr().abs()\n",
    "corr.drop(index='B_e_hat_residual_si_model_abs', inplace=True)\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "corr.plot(y='B_e_hat_residual_si_model_abs', kind='bar', ax=ax);\n",
    "ax.set_title('Absolut correlation coefficient for the error');\n",
    "ax.legend().remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_='$R^2$'\n",
    "number_of_points = 'Number of points'\n",
    "\n",
    "validation = pd.DataFrame(columns=[mean_, number_of_points])\n",
    "\n",
    "s = pd.Series(name='Ikeda')\n",
    "s[mean_] = r2_score(y_true=df_compare_all['B_e_hat'], y_pred=df_compare_all['B_e_hat_ikeda'])\n",
    "s[number_of_points] = int(len(df_compare_all))\n",
    "validation=validation.append(s)\n",
    "\n",
    "s = pd.Series(name='SI no limits')\n",
    "s[mean_] = r2_score(y_true=df_compare_all['B_e_hat'], y_pred=df_compare_all['B_e_hat_si'])\n",
    "s[number_of_points] = int(len(df_compare_all))\n",
    "validation=validation.append(s)\n",
    "\n",
    "validation[number_of_points]=validation[number_of_points].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex = validation.to_latex(float_format='%0.2f', na_rep='')\n",
    "name='si_ikeda_validation'\n",
    "file_path = os.path.join(rolldecay.equations_path,name)\n",
    "\n",
    "# (Uncomment this one if you want to regenerate this table)\n",
    "paper_writing.save_table(file_path=file_path, tabular_tex=latex, label='tab:si_ikeda_validation', \n",
    "           caption='Validation of SI and Ikeda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_compare_all['id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_compare_all['loading_condition_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_compare_all['model_number'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_compare_all['draught']=(df_compare['TA'] + df_compare['TF'])/2\n",
    "\n",
    "df_compare_all['CB'] = df_compare_all['Volume']/(df_compare_all['lpp']*df_compare_all['beam']*df_compare_all['draught'])\n",
    "df_compare_all['g'] = 9.81\n",
    "df_compare_all[r'B/d']=df_compare_all['beam']/df_compare_all['draught']\n",
    "df_compare_all['OG']=df_compare_all['draught']-df_compare_all['kg']\n",
    "df_compare_all[r'OG/d']=df_compare_all['OG']/df_compare_all['draught']\n",
    "df_compare_all['CMID']=df_compare_all['A0']\n",
    "df_compare_all[r'bBk/B']=df_compare_all['BKB']/df_compare_all['beam']\n",
    "df_compare_all[r'lBk/LPP']=df_compare_all['BKL']/df_compare_all['lpp']\n",
    "df_compare_all['OMEGA_hat']=lambdas.omega_hat(beam=df_compare_all['beam'], g=df_compare_all['g'], omega0=df_compare_all['omega0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rolldecayestimators.simplified_ikeda import limits_kawahara\n",
    "limits_kawahara=pd.Series(limits_kawahara)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(df, limits, item):\n",
    "    df=df.copy()\n",
    "    mask = ((df[item] >= limits[0]) & (df[item] <= limits[1])) | (df[item]==0)\n",
    "    df=df.loc[mask].copy()\n",
    "    return df\n",
    "\n",
    "def plot_select(df_compare, limits_used):\n",
    "    \n",
    "    df_compare_within = df_compare.copy()\n",
    "\n",
    "    fig,axes=plt.subplots(nrows=len(limits_used))\n",
    "    fig.set_size_inches(15,12)\n",
    "    \n",
    "    for (item, limits),ax in zip(limits_used.items(),axes):\n",
    "        \n",
    "        n_bins = 20\n",
    "        bins=np.linspace(df_compare[item].min(), df_compare[item].max(),n_bins)\n",
    "        df_compare.hist(item, ax=ax, bins=bins, color='gray')\n",
    "        \n",
    "        df_compare_within = cut(df=df_compare_within, limits=limits, item=item)\n",
    "        df_compare_within.hist(item, ax=ax, bins=bins, color='blue')\n",
    "        ax.set_xlabel(item)\n",
    "        ax.set_title('')\n",
    "        \n",
    "        ylims = ax.get_ylim()\n",
    "        ax.fill_between(limits, [ylims[1],ylims[1]], y2=0, color='green', alpha=0.5, label='valid')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    return df_compare_within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = plot_select(df_compare_all, limits_kawahara)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
